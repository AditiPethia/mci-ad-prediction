{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10794d00-4ed4-4f1a-8ed8-01b803b69187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> BOOT: SKSURV_OK = True | Python: 3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:07:17) [Clang 14.0.6 ]\n",
      "\n",
      "== RUN CONFIG ==\n",
      "csv_path: file path redacted for privacy",
      "outdir: file path redacted for privacy",
      "ENABLE_PENALIZED: True\n",
      "\n",
      "== STEP 1/6: Load dataset ==\n",
      "Loaded 197 rows | clinical cols=['Age', 'Sex', 'apoe4'] | miRNA features=2,562 | 0.23s\n",
      "[EDA] Saved basic EDA CSVs/plots to file path redacted for privacy",
      "\n",
      "== STEP 2/6: Train/Test split ==\n",
      "Train n=147, Test n=50 | Test events=21 (42.0%)\n",
      "[Baseline] Wrote summary CSVs to: file path redacted for privacy",
      "\n",
      "== STEP 2/6: Clinical Cox ==\n",
      "[KM] Saved outputs/km_by_risk_tertiles_clinical.png using 3 bins: ['Low', 'Mid', 'High']\n",
      "Proportional hazard assumption looks okay.\n",
      "PH assumption: OK\n",
      "Clinical Cox -> C-index=0.605, AUC@12/24/36=(0.728, 0.685, 0.578), saved HRs outputs/clinical_cox_hazard_ratios.csv, KM outputs/km_by_risk_tertiles_clinical.png | 0.12s\n",
      "\n",
      "== STEP 3/6: Prep survival objects ==\n",
      "\n",
      "== STEP 4/6: Supervised screen + correlation prune (TRAIN ONLY) ==\n",
      "[Screen] Tested 2562 miRNAs; BH q≤0.20: 0; keeping 100 (max 100)\n",
      "After FDR screen: 100 features\n",
      "After correlation prune: 75 features\n",
      "\n",
      "== STEP 5/6: Penalized Cox (miRNA-only, One-SE) ==\n",
      "Inner-CV (One-SE) search: l1_ratio_list= (1.0, 0.5, 0.2) | alphas ~ 0.1 ... 15.848931924611133\n",
      "  Fold 1/5 done\n",
      "  Fold 2/5 done\n",
      "  Fold 3/5 done\n",
      "  Fold 4/5 done\n",
      "  Fold 5/5 done\n",
      "CV best mean C=0.586, SD=0.118 -> One-SE threshold=0.468\n",
      "Selected: l1=1.00, alpha=0.1, CV mean=0.564 (±0.114)\n",
      "Final refit: non-zero features = 1\n",
      "[KM] Saved outputs/km_by_risk_tertiles_miRNA_coxnet.png using 3 bins: ['Low', 'Mid', 'High']\n",
      "[KM] KM saved -> outputs/km_by_risk_tertiles_miRNA_coxnet.png\n",
      "miRNA_coxnet: C=0.550, AUC@12/24/36=(0.643, 0.547, 0.597), non-zero=1, saved coefs=outputs/miRNA_coxnet_nonzero_coeffs.csv, KM=outputs/km_by_risk_tertiles_miRNA_coxnet.png | 0.09s\n",
      "The ``p_value_threshold`` is set at 0.05. Even under the null hypothesis of no violations, some\n",
      "covariates will be below the threshold by chance. This is compounded when there are many covariates.\n",
      "Similarly, when there are lots of observations, even minor deviances from the proportional hazard\n",
      "assumption will be flagged.\n",
      "\n",
      "With that in mind, it's best to use a combination of statistical tests and visual tests to determine\n",
      "the most serious violations. Produce visual plots using ``check_assumptions(..., show_plots=True)``\n",
      "and looking for non-constant lines. See link [A] below for a full example.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>null_distribution</th>\n",
       "      <td>chi squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degrees_of_freedom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>&lt;lifelines.CoxPHFitter: fitted with 147 total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_name</th>\n",
       "      <td>proportional_hazard_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_statistic</th>\n",
       "      <th>p</th>\n",
       "      <th>-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0000062</th>\n",
       "      <th>km</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019904</th>\n",
       "      <th>km</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019906</th>\n",
       "      <th>km</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019908</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019909</th>\n",
       "      <th>km</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019910</th>\n",
       "      <th>km</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019912</th>\n",
       "      <th>km</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019913</th>\n",
       "      <th>km</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019915</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019917</th>\n",
       "      <th>km</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019919</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019921</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019922</th>\n",
       "      <th>km</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019964</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019965</th>\n",
       "      <th>km</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019966</th>\n",
       "      <th>km</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019967</th>\n",
       "      <th>km</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019969</th>\n",
       "      <th>km</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019970</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019972</th>\n",
       "      <th>km</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019973</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019976</th>\n",
       "      <th>km</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019978</th>\n",
       "      <th>km</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019979</th>\n",
       "      <th>km</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019981</th>\n",
       "      <th>km</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019982</th>\n",
       "      <th>km</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019983</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0019985</th>\n",
       "      <th>km</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020300</th>\n",
       "      <th>km</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020541</th>\n",
       "      <th>km</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020600</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020601</th>\n",
       "      <th>km</th>\n",
       "      <td>1.85</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>2.62</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020602</th>\n",
       "      <th>km</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020603</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020924</th>\n",
       "      <th>km</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020925</th>\n",
       "      <th>km</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020956</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020957</th>\n",
       "      <th>km</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0020958</th>\n",
       "      <th>km</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021017</th>\n",
       "      <th>km</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021018</th>\n",
       "      <th>km</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021020</th>\n",
       "      <th>km</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021021</th>\n",
       "      <th>km</th>\n",
       "      <td>1.66</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>2.59</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021022</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021024</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021027</th>\n",
       "      <th>km</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021028</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021029</th>\n",
       "      <th>km</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021030</th>\n",
       "      <th>km</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021033</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021034</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021035</th>\n",
       "      <th>km</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021037</th>\n",
       "      <th>km</th>\n",
       "      <td>1.67</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.84</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021038</th>\n",
       "      <th>km</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021039</th>\n",
       "      <th>km</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021040</th>\n",
       "      <th>km</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021042</th>\n",
       "      <th>km</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021043</th>\n",
       "      <th>km</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021044</th>\n",
       "      <th>km</th>\n",
       "      <td>2.94</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>4.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021079</th>\n",
       "      <th>km</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021080</th>\n",
       "      <th>km</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021081</th>\n",
       "      <th>km</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021082</th>\n",
       "      <th>km</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021083</th>\n",
       "      <th>km</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021084</th>\n",
       "      <th>km</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021085</th>\n",
       "      <th>km</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021086</th>\n",
       "      <th>km</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021116</th>\n",
       "      <th>km</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021117</th>\n",
       "      <th>km</th>\n",
       "      <td>1.05</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.51</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021118</th>\n",
       "      <th>km</th>\n",
       "      <td>1.17</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021119</th>\n",
       "      <th>km</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021120</th>\n",
       "      <th>km</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021121</th>\n",
       "      <th>km</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021123</th>\n",
       "      <th>km</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MIMAT0021124</th>\n",
       "      <th>km</th>\n",
       "      <td>1.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <td>1.76</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{tabular}{llrrr}\n",
       " &  & test_statistic & p & -log2(p) \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0000062} & km & 0.09 & 0.77 & 0.38 \\\\\n",
       " & rank & 0.03 & 0.86 & 0.22 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019904} & km & 0.48 & 0.49 & 1.03 \\\\\n",
       " & rank & 0.39 & 0.53 & 0.90 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019906} & km & 0.45 & 0.50 & 0.99 \\\\\n",
       " & rank & 0.75 & 0.39 & 1.37 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019908} & km & 0.00 & 0.97 & 0.04 \\\\\n",
       " & rank & 0.01 & 0.91 & 0.14 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019909} & km & 0.08 & 0.77 & 0.38 \\\\\n",
       " & rank & 0.12 & 0.72 & 0.47 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019910} & km & 0.30 & 0.58 & 0.78 \\\\\n",
       " & rank & 0.40 & 0.53 & 0.92 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019912} & km & 0.48 & 0.49 & 1.03 \\\\\n",
       " & rank & 0.68 & 0.41 & 1.29 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019913} & km & 0.14 & 0.71 & 0.49 \\\\\n",
       " & rank & 0.07 & 0.79 & 0.33 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019915} & km & 0.00 & 0.96 & 0.05 \\\\\n",
       " & rank & 0.00 & 0.96 & 0.05 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019917} & km & 0.07 & 0.79 & 0.34 \\\\\n",
       " & rank & 0.37 & 0.54 & 0.88 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019919} & km & 0.01 & 0.93 & 0.11 \\\\\n",
       " & rank & 0.02 & 0.88 & 0.18 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019921} & km & 0.01 & 0.94 & 0.09 \\\\\n",
       " & rank & 0.02 & 0.88 & 0.18 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019922} & km & 0.02 & 0.90 & 0.16 \\\\\n",
       " & rank & 0.03 & 0.87 & 0.20 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019964} & km & 0.00 & 0.96 & 0.07 \\\\\n",
       " & rank & 0.00 & 0.99 & 0.01 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019965} & km & 0.20 & 0.66 & 0.61 \\\\\n",
       " & rank & 0.21 & 0.65 & 0.62 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019966} & km & 0.07 & 0.80 & 0.32 \\\\\n",
       " & rank & 0.27 & 0.60 & 0.74 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019967} & km & 0.49 & 0.49 & 1.04 \\\\\n",
       " & rank & 0.33 & 0.56 & 0.83 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019969} & km & 0.02 & 0.90 & 0.15 \\\\\n",
       " & rank & 0.03 & 0.86 & 0.22 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019970} & km & 0.00 & 0.98 & 0.04 \\\\\n",
       " & rank & 0.00 & 0.96 & 0.05 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019972} & km & 0.10 & 0.75 & 0.41 \\\\\n",
       " & rank & 0.11 & 0.74 & 0.44 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019973} & km & 0.01 & 0.93 & 0.10 \\\\\n",
       " & rank & 0.02 & 0.88 & 0.18 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019976} & km & 0.09 & 0.76 & 0.40 \\\\\n",
       " & rank & 0.23 & 0.63 & 0.66 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019978} & km & 0.42 & 0.52 & 0.95 \\\\\n",
       " & rank & 0.17 & 0.68 & 0.55 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019979} & km & 0.08 & 0.77 & 0.37 \\\\\n",
       " & rank & 0.12 & 0.72 & 0.47 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019981} & km & 0.17 & 0.68 & 0.55 \\\\\n",
       " & rank & 0.14 & 0.71 & 0.49 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019982} & km & 0.12 & 0.73 & 0.46 \\\\\n",
       " & rank & 0.23 & 0.63 & 0.66 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019983} & km & 0.00 & 0.97 & 0.04 \\\\\n",
       " & rank & 0.01 & 0.93 & 0.11 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0019985} & km & 0.11 & 0.74 & 0.43 \\\\\n",
       " & rank & 0.09 & 0.77 & 0.38 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020300} & km & 0.03 & 0.86 & 0.22 \\\\\n",
       " & rank & 0.04 & 0.84 & 0.25 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020541} & km & 0.02 & 0.89 & 0.17 \\\\\n",
       " & rank & 0.01 & 0.91 & 0.14 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020600} & km & 0.00 & 0.95 & 0.07 \\\\\n",
       " & rank & 0.04 & 0.83 & 0.26 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020601} & km & 1.85 & 0.17 & 2.53 \\\\\n",
       " & rank & 2.62 & 0.11 & 3.24 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020602} & km & 0.21 & 0.65 & 0.63 \\\\\n",
       " & rank & 0.31 & 0.58 & 0.78 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020603} & km & 0.00 & 0.97 & 0.04 \\\\\n",
       " & rank & 0.01 & 0.94 & 0.08 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020924} & km & 0.98 & 0.32 & 1.64 \\\\\n",
       " & rank & 1.33 & 0.25 & 2.01 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020925} & km & 0.08 & 0.78 & 0.36 \\\\\n",
       " & rank & 0.12 & 0.73 & 0.45 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020956} & km & 0.01 & 0.92 & 0.13 \\\\\n",
       " & rank & 0.03 & 0.85 & 0.23 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020957} & km & 0.21 & 0.65 & 0.63 \\\\\n",
       " & rank & 0.32 & 0.57 & 0.80 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0020958} & km & 0.05 & 0.82 & 0.28 \\\\\n",
       " & rank & 0.06 & 0.80 & 0.32 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021017} & km & 0.06 & 0.81 & 0.30 \\\\\n",
       " & rank & 0.11 & 0.74 & 0.44 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021018} & km & 0.04 & 0.85 & 0.24 \\\\\n",
       " & rank & 0.05 & 0.82 & 0.29 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021020} & km & 0.25 & 0.61 & 0.70 \\\\\n",
       " & rank & 0.39 & 0.53 & 0.91 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021021} & km & 1.66 & 0.20 & 2.34 \\\\\n",
       " & rank & 2.59 & 0.11 & 3.21 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021022} & km & 0.00 & 0.95 & 0.07 \\\\\n",
       " & rank & 0.02 & 0.89 & 0.16 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021024} & km & 0.00 & 0.96 & 0.06 \\\\\n",
       " & rank & 0.00 & 0.96 & 0.06 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021027} & km & 0.58 & 0.45 & 1.16 \\\\\n",
       " & rank & 0.94 & 0.33 & 1.59 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021028} & km & 0.00 & 1.00 & 0.01 \\\\\n",
       " & rank & 0.00 & 0.99 & 0.02 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021029} & km & 0.08 & 0.77 & 0.37 \\\\\n",
       " & rank & 0.31 & 0.58 & 0.79 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021030} & km & 0.04 & 0.84 & 0.26 \\\\\n",
       " & rank & 0.01 & 0.92 & 0.12 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021033} & km & 0.01 & 0.93 & 0.10 \\\\\n",
       " & rank & 0.03 & 0.85 & 0.23 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021034} & km & 0.01 & 0.93 & 0.11 \\\\\n",
       " & rank & 0.03 & 0.87 & 0.19 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021035} & km & 0.14 & 0.71 & 0.50 \\\\\n",
       " & rank & 0.19 & 0.67 & 0.59 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021037} & km & 1.67 & 0.20 & 2.35 \\\\\n",
       " & rank & 1.84 & 0.17 & 2.52 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021038} & km & 0.07 & 0.79 & 0.33 \\\\\n",
       " & rank & 0.05 & 0.83 & 0.27 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021039} & km & 0.10 & 0.76 & 0.40 \\\\\n",
       " & rank & 0.18 & 0.67 & 0.58 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021040} & km & 0.93 & 0.33 & 1.58 \\\\\n",
       " & rank & 1.11 & 0.29 & 1.78 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021042} & km & 0.17 & 0.68 & 0.55 \\\\\n",
       " & rank & 0.20 & 0.66 & 0.60 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021043} & km & 0.75 & 0.39 & 1.37 \\\\\n",
       " & rank & 0.56 & 0.45 & 1.14 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021044} & km & 2.94 & 0.09 & 3.53 \\\\\n",
       " & rank & 4.06 & 0.04 & 4.51 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021079} & km & 0.13 & 0.72 & 0.47 \\\\\n",
       " & rank & 0.02 & 0.88 & 0.18 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021080} & km & 0.17 & 0.68 & 0.56 \\\\\n",
       " & rank & 0.55 & 0.46 & 1.13 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021081} & km & 0.09 & 0.76 & 0.39 \\\\\n",
       " & rank & 0.14 & 0.71 & 0.50 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021082} & km & 0.36 & 0.55 & 0.86 \\\\\n",
       " & rank & 0.26 & 0.61 & 0.72 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021083} & km & 0.01 & 0.94 & 0.10 \\\\\n",
       " & rank & 0.01 & 0.93 & 0.10 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021084} & km & 0.00 & 0.96 & 0.07 \\\\\n",
       " & rank & 0.00 & 0.96 & 0.06 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021085} & km & 0.90 & 0.34 & 1.54 \\\\\n",
       " & rank & 1.02 & 0.31 & 1.68 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021086} & km & 0.02 & 0.89 & 0.18 \\\\\n",
       " & rank & 0.01 & 0.92 & 0.11 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021116} & km & 0.16 & 0.69 & 0.54 \\\\\n",
       " & rank & 0.20 & 0.65 & 0.62 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021117} & km & 1.05 & 0.31 & 1.71 \\\\\n",
       " & rank & 1.51 & 0.22 & 2.19 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021118} & km & 1.17 & 0.28 & 1.84 \\\\\n",
       " & rank & 1.42 & 0.23 & 2.10 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021119} & km & 0.53 & 0.47 & 1.09 \\\\\n",
       " & rank & 0.69 & 0.41 & 1.30 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021120} & km & 0.09 & 0.76 & 0.40 \\\\\n",
       " & rank & 0.16 & 0.69 & 0.54 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021121} & km & 0.61 & 0.44 & 1.20 \\\\\n",
       " & rank & 0.70 & 0.40 & 1.31 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021123} & km & 0.10 & 0.76 & 0.40 \\\\\n",
       " & rank & 0.30 & 0.58 & 0.78 \\\\\n",
       "\\multirow[c]{2}{*}{MIMAT0021124} & km & 1.42 & 0.23 & 2.10 \\\\\n",
       " & rank & 1.76 & 0.18 & 2.44 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.StatisticalResult: proportional_hazard_test>\n",
       " null_distribution = chi squared\n",
       "degrees_of_freedom = 1\n",
       "             model = <lifelines.CoxPHFitter: fitted with 147 total observations, 85 right-censored observations>\n",
       "         test_name = proportional_hazard_test\n",
       "\n",
       "---\n",
       "                   test_statistic    p  -log2(p)\n",
       "MIMAT0000062 km              0.09 0.77      0.38\n",
       "             rank            0.03 0.86      0.22\n",
       "MIMAT0019904 km              0.48 0.49      1.03\n",
       "             rank            0.39 0.53      0.90\n",
       "MIMAT0019906 km              0.45 0.50      0.99\n",
       "             rank            0.75 0.39      1.37\n",
       "MIMAT0019908 km              0.00 0.97      0.04\n",
       "             rank            0.01 0.91      0.14\n",
       "MIMAT0019909 km              0.08 0.77      0.38\n",
       "             rank            0.12 0.72      0.47\n",
       "MIMAT0019910 km              0.30 0.58      0.78\n",
       "             rank            0.40 0.53      0.92\n",
       "MIMAT0019912 km              0.48 0.49      1.03\n",
       "             rank            0.68 0.41      1.29\n",
       "MIMAT0019913 km              0.14 0.71      0.49\n",
       "             rank            0.07 0.79      0.33\n",
       "MIMAT0019915 km              0.00 0.96      0.05\n",
       "             rank            0.00 0.96      0.05\n",
       "MIMAT0019917 km              0.07 0.79      0.34\n",
       "             rank            0.37 0.54      0.88\n",
       "MIMAT0019919 km              0.01 0.93      0.11\n",
       "             rank            0.02 0.88      0.18\n",
       "MIMAT0019921 km              0.01 0.94      0.09\n",
       "             rank            0.02 0.88      0.18\n",
       "MIMAT0019922 km              0.02 0.90      0.16\n",
       "             rank            0.03 0.87      0.20\n",
       "MIMAT0019964 km              0.00 0.96      0.07\n",
       "             rank            0.00 0.99      0.01\n",
       "MIMAT0019965 km              0.20 0.66      0.61\n",
       "             rank            0.21 0.65      0.62\n",
       "MIMAT0019966 km              0.07 0.80      0.32\n",
       "             rank            0.27 0.60      0.74\n",
       "MIMAT0019967 km              0.49 0.49      1.04\n",
       "             rank            0.33 0.56      0.83\n",
       "MIMAT0019969 km              0.02 0.90      0.15\n",
       "             rank            0.03 0.86      0.22\n",
       "MIMAT0019970 km              0.00 0.98      0.04\n",
       "             rank            0.00 0.96      0.05\n",
       "MIMAT0019972 km              0.10 0.75      0.41\n",
       "             rank            0.11 0.74      0.44\n",
       "MIMAT0019973 km              0.01 0.93      0.10\n",
       "             rank            0.02 0.88      0.18\n",
       "MIMAT0019976 km              0.09 0.76      0.40\n",
       "             rank            0.23 0.63      0.66\n",
       "MIMAT0019978 km              0.42 0.52      0.95\n",
       "             rank            0.17 0.68      0.55\n",
       "MIMAT0019979 km              0.08 0.77      0.37\n",
       "             rank            0.12 0.72      0.47\n",
       "MIMAT0019981 km              0.17 0.68      0.55\n",
       "             rank            0.14 0.71      0.49\n",
       "MIMAT0019982 km              0.12 0.73      0.46\n",
       "             rank            0.23 0.63      0.66\n",
       "MIMAT0019983 km              0.00 0.97      0.04\n",
       "             rank            0.01 0.93      0.11\n",
       "MIMAT0019985 km              0.11 0.74      0.43\n",
       "             rank            0.09 0.77      0.38\n",
       "MIMAT0020300 km              0.03 0.86      0.22\n",
       "             rank            0.04 0.84      0.25\n",
       "MIMAT0020541 km              0.02 0.89      0.17\n",
       "             rank            0.01 0.91      0.14\n",
       "MIMAT0020600 km              0.00 0.95      0.07\n",
       "             rank            0.04 0.83      0.26\n",
       "MIMAT0020601 km              1.85 0.17      2.53\n",
       "             rank            2.62 0.11      3.24\n",
       "MIMAT0020602 km              0.21 0.65      0.63\n",
       "             rank            0.31 0.58      0.78\n",
       "MIMAT0020603 km              0.00 0.97      0.04\n",
       "             rank            0.01 0.94      0.08\n",
       "MIMAT0020924 km              0.98 0.32      1.64\n",
       "             rank            1.33 0.25      2.01\n",
       "MIMAT0020925 km              0.08 0.78      0.36\n",
       "             rank            0.12 0.73      0.45\n",
       "MIMAT0020956 km              0.01 0.92      0.13\n",
       "             rank            0.03 0.85      0.23\n",
       "MIMAT0020957 km              0.21 0.65      0.63\n",
       "             rank            0.32 0.57      0.80\n",
       "MIMAT0020958 km              0.05 0.82      0.28\n",
       "             rank            0.06 0.80      0.32\n",
       "MIMAT0021017 km              0.06 0.81      0.30\n",
       "             rank            0.11 0.74      0.44\n",
       "MIMAT0021018 km              0.04 0.85      0.24\n",
       "             rank            0.05 0.82      0.29\n",
       "MIMAT0021020 km              0.25 0.61      0.70\n",
       "             rank            0.39 0.53      0.91\n",
       "MIMAT0021021 km              1.66 0.20      2.34\n",
       "             rank            2.59 0.11      3.21\n",
       "MIMAT0021022 km              0.00 0.95      0.07\n",
       "             rank            0.02 0.89      0.16\n",
       "MIMAT0021024 km              0.00 0.96      0.06\n",
       "             rank            0.00 0.96      0.06\n",
       "MIMAT0021027 km              0.58 0.45      1.16\n",
       "             rank            0.94 0.33      1.59\n",
       "MIMAT0021028 km              0.00 1.00      0.01\n",
       "             rank            0.00 0.99      0.02\n",
       "MIMAT0021029 km              0.08 0.77      0.37\n",
       "             rank            0.31 0.58      0.79\n",
       "MIMAT0021030 km              0.04 0.84      0.26\n",
       "             rank            0.01 0.92      0.12\n",
       "MIMAT0021033 km              0.01 0.93      0.10\n",
       "             rank            0.03 0.85      0.23\n",
       "MIMAT0021034 km              0.01 0.93      0.11\n",
       "             rank            0.03 0.87      0.19\n",
       "MIMAT0021035 km              0.14 0.71      0.50\n",
       "             rank            0.19 0.67      0.59\n",
       "MIMAT0021037 km              1.67 0.20      2.35\n",
       "             rank            1.84 0.17      2.52\n",
       "MIMAT0021038 km              0.07 0.79      0.33\n",
       "             rank            0.05 0.83      0.27\n",
       "MIMAT0021039 km              0.10 0.76      0.40\n",
       "             rank            0.18 0.67      0.58\n",
       "MIMAT0021040 km              0.93 0.33      1.58\n",
       "             rank            1.11 0.29      1.78\n",
       "MIMAT0021042 km              0.17 0.68      0.55\n",
       "             rank            0.20 0.66      0.60\n",
       "MIMAT0021043 km              0.75 0.39      1.37\n",
       "             rank            0.56 0.45      1.14\n",
       "MIMAT0021044 km              2.94 0.09      3.53\n",
       "             rank            4.06 0.04      4.51\n",
       "MIMAT0021079 km              0.13 0.72      0.47\n",
       "             rank            0.02 0.88      0.18\n",
       "MIMAT0021080 km              0.17 0.68      0.56\n",
       "             rank            0.55 0.46      1.13\n",
       "MIMAT0021081 km              0.09 0.76      0.39\n",
       "             rank            0.14 0.71      0.50\n",
       "MIMAT0021082 km              0.36 0.55      0.86\n",
       "             rank            0.26 0.61      0.72\n",
       "MIMAT0021083 km              0.01 0.94      0.10\n",
       "             rank            0.01 0.93      0.10\n",
       "MIMAT0021084 km              0.00 0.96      0.07\n",
       "             rank            0.00 0.96      0.06\n",
       "MIMAT0021085 km              0.90 0.34      1.54\n",
       "             rank            1.02 0.31      1.68\n",
       "MIMAT0021086 km              0.02 0.89      0.18\n",
       "             rank            0.01 0.92      0.11\n",
       "MIMAT0021116 km              0.16 0.69      0.54\n",
       "             rank            0.20 0.65      0.62\n",
       "MIMAT0021117 km              1.05 0.31      1.71\n",
       "             rank            1.51 0.22      2.19\n",
       "MIMAT0021118 km              1.17 0.28      1.84\n",
       "             rank            1.42 0.23      2.10\n",
       "MIMAT0021119 km              0.53 0.47      1.09\n",
       "             rank            0.69 0.41      1.30\n",
       "MIMAT0021120 km              0.09 0.76      0.40\n",
       "             rank            0.16 0.69      0.54\n",
       "MIMAT0021121 km              0.61 0.44      1.20\n",
       "             rank            0.70 0.40      1.31\n",
       "MIMAT0021123 km              0.10 0.76      0.40\n",
       "             rank            0.30 0.58      0.78\n",
       "MIMAT0021124 km              1.42 0.23      2.10\n",
       "             rank            1.76 0.18      2.44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Variable 'MIMAT0021044' failed the non-proportional test: p-value is 0.0440.\n",
      "\n",
      "   Advice 1: the functional form of the variable 'MIMAT0021044' might be incorrect. That is, there\n",
      "may be non-linear terms missing. The proportional hazard test used is very sensitive to incorrect\n",
      "functional forms. See documentation in link [D] below on how to specify a functional form.\n",
      "\n",
      "   Advice 2: try binning the variable 'MIMAT0021044' using pd.cut, and then specify it in\n",
      "`strata=['MIMAT0021044', ...]` in the call in `.fit`. See documentation in link [B] below.\n",
      "\n",
      "   Advice 3: try adding an interaction term with your time variable. See documentation in link [C]\n",
      "below.\n",
      "\n",
      "\n",
      "---\n",
      "[A]  https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html\n",
      "[B]  https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html#Bin-variable-and-stratify-on-it\n",
      "[C]  https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html#Introduce-time-varying-covariates\n",
      "[D]  https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html#Modify-the-functional-form\n",
      "[E]  https://lifelines.readthedocs.io/en/latest/jupyter_notebooks/Proportional%20hazard%20assumption.html#Stratification\n",
      "\n",
      "\n",
      "== STEP 6/6: Combined model (stack clinical LP only + miRNA) ==\n",
      "Inner-CV (One-SE) search: l1_ratio_list= (1.0, 0.5, 0.2) | alphas ~ 0.01 ... 15.848931924611133\n",
      "  Fold 1/5 done\n",
      "  Fold 2/5 done\n",
      "  Fold 3/5 done\n",
      "  Fold 4/5 done\n",
      "  Fold 5/5 done\n",
      "CV best mean C=0.624, SD=0.109 -> One-SE threshold=0.515\n",
      "Selected: l1=1.00, alpha=0.02121, CV mean=0.520 (±0.104)\n",
      "Final refit: non-zero features = 25\n",
      "[KM] Saved outputs/km_by_risk_tertiles_combined_coxnet.png using 3 bins: ['Low', 'Mid', 'High']\n",
      "[KM] KM saved -> outputs/km_by_risk_tertiles_combined_coxnet.png\n",
      "combined_coxnet: C=0.630, AUC@12/24/36=(0.750, 0.669, 0.642), non-zero=25, saved coefs=outputs/combined_coxnet_nonzero_coeffs.csv, KM=outputs/km_by_risk_tertiles_combined_coxnet.png | 0.10s\n",
      "Proportional hazard assumption looks okay.\n",
      "\n",
      "== DONE. See outputs/ ==\n",
      " - baseline_table_raw.csv\n",
      " - clinical_cox_hazard_ratios.csv\n",
      " - model_metrics.csv\n",
      " - km_by_risk_tertiles_clinical.png\n",
      " - miRNA_screened_features.csv\n",
      " - km_by_risk_tertiles_miRNA_coxnet.png\n",
      " - km_by_risk_tertiles_combined_coxnet.png\n",
      " - miRNA_coxnet_nonzero_coeffs.csv\n",
      " - combined_coxnet_nonzero_coeffs.csv\n",
      " - patient_level_predictions_test.csv\n",
      " - dca_clinical_24m.csv\n",
      " - metrics_subgroups_clinical.csv\n",
      " - requirements_freeze.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Predicting MCI→AD conversion (GSE150693-style) — clean pipeline\n",
    "# - No data leakage (train-only imputation)\n",
    "# - Clinical Cox (discrimination + calibration + IBS)\n",
    "# - miRNA screening + Coxnet (elastic-net, inner CV, one-SE)\n",
    "# - Combined model = clin_lp + selected miRNAs (no double counting)\n",
    "# - PH checks on refit CoxPH\n",
    "# - Bootstrap 95% CIs for discrimination\n",
    "# - Decision Curve Analysis (24m)\n",
    "# - Subgroup metrics (sex / age-high)\n",
    "# - Reproducibility freeze\n",
    "# ============================================================\n",
    "\n",
    "# --- toggles & quick diagnostics ---\n",
    "ENABLE_PENALIZED = True  # set False to run clinical-only while testing\n",
    "\n",
    "import os, sys, time, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# FDR control for univariate screen\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Classical Cox + KM (always present)\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.utils import concordance_index as ll_cindex\n",
    "\n",
    "# Optional survival ML (penalized Cox, metrics)\n",
    "SKSURV_OK = True\n",
    "try:\n",
    "    from sksurv.util import Surv\n",
    "    from sksurv.metrics import (\n",
    "        concordance_index_censored,\n",
    "        cumulative_dynamic_auc,\n",
    "        brier_score as sk_brier_score,\n",
    "        integrated_brier_score,\n",
    "    )\n",
    "    from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis\n",
    "    from sksurv.ensemble import RandomSurvivalForest\n",
    "except Exception as e:\n",
    "    SKSURV_OK = False\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print(\">>> BOOT: SKSURV_OK =\", SKSURV_OK, \"| Python:\", sys.version)\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Utility helpers\n",
    "# ---------------------------\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def to_surv(y_time_months: np.ndarray, y_event: np.ndarray):\n",
    "    if not SKSURV_OK:\n",
    "        raise RuntimeError(\"sksurv not available\")\n",
    "    return Surv.from_arrays(event=y_event.astype(bool), time=y_time_months.astype(float))\n",
    "\n",
    "def km_plot_by_tertiles(times, events, risk_scores, out_png, title):\n",
    "    \"\"\"\n",
    "    Robust KM by risk quantiles. Falls back to 2 bins if tertiles are not possible,\n",
    "    and skips plotting when risk is (near) constant.\n",
    "    \"\"\"\n",
    "    risk = pd.Series(np.asarray(risk_scores, dtype=float))\n",
    "    nunq = risk.nunique(dropna=True)\n",
    "    if nunq < 2:\n",
    "        print(f\"[KM] SKIP '{title}': risk has <2 unique values (nunique={nunq}).\")\n",
    "        return\n",
    "\n",
    "    bins = None\n",
    "    labels_present = []\n",
    "    try:\n",
    "        tert = pd.qcut(risk, q=3, labels=[\"Low\", \"Mid\", \"High\"], duplicates=\"drop\")\n",
    "        labs = [str(c) for c in tert.cat.categories]\n",
    "        labels_present = [lab for lab in [\"Low\", \"Mid\", \"High\"] if lab in labs]\n",
    "        if len(tert.cat.categories) >= 2:\n",
    "            bins = tert\n",
    "    except Exception:\n",
    "        bins = None\n",
    "\n",
    "    if bins is None or len(bins.cat.categories) < 2:\n",
    "        try:\n",
    "            halves = pd.qcut(risk, q=2, labels=[\"Low\", \"High\"], duplicates=\"drop\")\n",
    "            labs = [str(c) for c in halves.cat.categories]\n",
    "            labels_present = [lab for lab in [\"Low\", \"High\"] if lab in labs]\n",
    "            if len(halves.cat.categories) >= 2:\n",
    "                bins = halves\n",
    "        except Exception:\n",
    "            print(f\"[KM] SKIP '{title}': unable to bin risk (likely constant).\")\n",
    "            return\n",
    "\n",
    "    kmf = KaplanMeierFitter()\n",
    "    plt.figure()\n",
    "    for label in labels_present:\n",
    "        mask = (bins.astype(str).values == label)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        kmf.fit(times[mask], events[mask], label=f\"{label} risk\")\n",
    "        kmf.plot(ci_show=False)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (months)\")\n",
    "    plt.ylabel(\"Survival probability (no AD conversion)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"[KM] Saved {out_png} using {len(labels_present)} bins: {labels_present}\")\n",
    "\n",
    "def tidy_metric_row(model_name, cindex, auc12, auc24, auc36, note=\"\"):\n",
    "    return {\"model\": model_name, \"cindex\": cindex, \"auc_12m\": auc12,\n",
    "            \"auc_24m\": auc24, \"auc_36m\": auc36, \"note\": note}\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load & audit data\n",
    "# ---------------------------\n",
    "def load_dataset(csv_path: str):\n",
    "    print(\"\\n== STEP 1/6: Load dataset ==\")\n",
    "    t0 = time.perf_counter()\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required = [\"title\", \"Diagnosis\", \"Age\", \"Sex\", \"apoe4\", \"Day\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    time_months = (pd.to_numeric(df[\"Day\"], errors=\"coerce\") / 30.44).to_numpy()\n",
    "    event = (df[\"Diagnosis\"].astype(str) == \"MCI-C\").astype(int).to_numpy()\n",
    "\n",
    "    # NOTE: No imputation here (avoid leakage). Impute later, train-only.\n",
    "    X_clin = pd.DataFrame({\n",
    "        \"Age\": pd.to_numeric(df[\"Age\"], errors=\"coerce\"),\n",
    "        \"Sex\": (df[\"Sex\"].astype(str).str.lower() == \"male\").astype(int),\n",
    "        \"apoe4\": pd.to_numeric(df[\"apoe4\"], errors=\"coerce\")\n",
    "    })\n",
    "\n",
    "    mir_cols = [c for c in df.columns if c.startswith(\"MIMAT\")]\n",
    "    X_mir = df[mir_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    ids = df[\"title\"].astype(str).to_numpy()\n",
    "    print(f\"Loaded {len(df):,} rows | clinical cols={list(X_clin.columns)} | miRNA features={X_mir.shape[1]:,} | {time.perf_counter()-t0:.2f}s\")\n",
    "    return df, ids, time_months, event, X_clin, X_mir\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Split data (stratified)\n",
    "# ---------------------------\n",
    "def stratified_split(event, test_size=0.25, seed=123):\n",
    "    idx = np.arange(len(event))\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        idx, test_size=test_size, stratify=event, random_state=seed\n",
    "    )\n",
    "    return train_idx, test_idx\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Clinical-only Cox (lifelines)\n",
    "# ---------------------------\n",
    "def fit_evaluate_clinical_cox(X_tr, t_tr, e_tr, X_te, t_te, e_te, outdir):\n",
    "    print(\"\\n== STEP 2/6: Clinical Cox ==\")\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    df_train = pd.concat([\n",
    "        pd.DataFrame({\"time\": t_tr, \"event\": e_tr}),\n",
    "        X_tr.reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_train, duration_col=\"time\", event_col=\"event\", show_progress=False)\n",
    "\n",
    "    hr_path = os.path.join(outdir, \"clinical_cox_hazard_ratios.csv\")\n",
    "    hr = cph.summary[[\"coef\", \"exp(coef)\", \"se(coef)\", \"p\",\n",
    "                      \"exp(coef) lower 95%\", \"exp(coef) upper 95%\"]]\n",
    "    hr.to_csv(hr_path)\n",
    "\n",
    "    # lifelines partial hazard: larger = higher risk (shorter survival).\n",
    "    risk_scores_test = cph.predict_partial_hazard(X_te).to_numpy().ravel()\n",
    "\n",
    "    # Default NaNs\n",
    "    auc12 = auc24 = auc36 = np.nan\n",
    "    cidx = np.nan\n",
    "\n",
    "    if SKSURV_OK:\n",
    "        y_tr = to_surv(t_tr, e_tr)\n",
    "        y_te = to_surv(t_te, e_te)\n",
    "\n",
    "        # C-index (fine for any times)\n",
    "        cidx = concordance_index_censored(e_te.astype(bool), t_te, risk_scores_test)[0]\n",
    "\n",
    "        # Time-dependent AUC at safe times only\n",
    "        desired = np.array([12, 24, 36], dtype=float)\n",
    "        safe_t = _safe_auc_times(t_te, desired)\n",
    "        if safe_t.size > 0:\n",
    "            aucs, _ = cumulative_dynamic_auc(y_tr, y_te, risk_scores_test, times=safe_t)\n",
    "            # map back to 12/24/36 (NaN if not computed)\n",
    "            for t_val, a in zip(safe_t, aucs):\n",
    "                if np.isclose(t_val, 12): auc12 = float(a)\n",
    "                if np.isclose(t_val, 24): auc24 = float(a)\n",
    "                if np.isclose(t_val, 36): auc36 = float(a)\n",
    "    else:\n",
    "        cidx = float(ll_cindex(t_te, risk_scores_test, e_te))\n",
    "\n",
    "    km_path = os.path.join(outdir, \"km_by_risk_tertiles_clinical.png\")\n",
    "    km_plot_by_tertiles(t_te, e_te, risk_scores_test, km_path,\n",
    "                        \"Kaplan–Meier by risk tertile (Clinical Cox, test set)\")\n",
    "\n",
    "    try:\n",
    "        cph.check_assumptions(df_train, p_value_threshold=0.05, show_plots=False)\n",
    "        print(\"PH assumption: OK\")\n",
    "    except Exception as ex:\n",
    "        print(\"PH assumption check skipped:\", type(ex).__name__)\n",
    "\n",
    "    print(f\"Clinical Cox -> C-index={cidx:.3f}, AUC@12/24/36=({auc12:.3f}, {auc24:.3f}, {auc36:.3f}), \"\n",
    "          f\"saved HRs {hr_path}, KM {km_path} | {time.perf_counter()-t0:.2f}s\")\n",
    "    return cph, risk_scores_test, tidy_metric_row(\"Clinical Cox\", cidx, auc12, auc24, auc36, note=\"unpenalized\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Feature screening + Penalized CoxNet\n",
    "# ---------------------------\n",
    "def univariate_screen(X_train, y_train_surv, fdr=0.20, max_keep=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Supervised univariate Cox screening on TRAIN ONLY.\n",
    "    Returns list of selected column names.\n",
    "    \"\"\"\n",
    "    t = np.asarray(y_train_surv[\"time\"], dtype=float)\n",
    "    e = np.asarray(y_train_surv[\"event\"], dtype=bool).astype(int)\n",
    "\n",
    "    pvals = []\n",
    "    cols  = list(X_train.columns)\n",
    "    for col in cols:\n",
    "        df = pd.DataFrame({\"time\": t, \"event\": e, col: X_train[col].values})\n",
    "        try:\n",
    "            cph = CoxPHFitter()\n",
    "            cph.fit(df, duration_col=\"time\", event_col=\"event\", show_progress=False)\n",
    "            p = float(cph.summary.loc[col, \"p\"])\n",
    "        except Exception:\n",
    "            p = 1.0\n",
    "        pvals.append(p)\n",
    "\n",
    "    pvals = np.array(pvals)\n",
    "    _, qvals, _, _ = multipletests(pvals, alpha=fdr, method=\"fdr_bh\")\n",
    "\n",
    "    keep_mask = qvals <= fdr\n",
    "    keep = [cols[i] for i, ok in enumerate(keep_mask) if ok]\n",
    "\n",
    "    if len(keep) == 0:\n",
    "        order = np.argsort(qvals)\n",
    "        keep = [cols[i] for i in order[:max_keep]]\n",
    "    elif len(keep) > max_keep:\n",
    "        order = np.argsort(qvals[keep_mask])[:max_keep]\n",
    "        keep = [np.array(cols)[keep_mask][k] for k in order]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[Screen] Tested {len(cols)} miRNAs; BH q≤{fdr:.2f}: {(qvals<=fdr).sum()}; keeping {len(keep)} (max {max_keep})\")\n",
    "    return keep\n",
    "\n",
    "def correlation_prune(X_train, threshold=0.85):\n",
    "    \"\"\"Drop one from each pair of features with |corr| > threshold.\"\"\"\n",
    "    X = X_train.astype(float)\n",
    "    corr = X.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = set([column for column in upper.columns if any(upper[column] > threshold)])\n",
    "    kept = [c for c in X.columns if c not in to_drop]\n",
    "    return kept\n",
    "\n",
    "def fit_select_coxnet_innercv_onese(\n",
    "    X_train, y_train,\n",
    "    l1_ratio_list=(1.0, 0.5, 0.2),\n",
    "    alpha_grid=np.logspace(-1, 1.2, 30),\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "):\n",
    "    alpha_scores = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    print(\"Inner-CV (One-SE) search: l1_ratio_list=\", l1_ratio_list, \"| alphas ~\", alpha_grid[0], \"...\", alpha_grid[-1])\n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train), 1):\n",
    "        Xtr, Xva = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        ytr, yva = y_train[tr_idx], y_train[va_idx]\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "        Xtr_std = scaler.fit_transform(Xtr)\n",
    "        Xva_std = scaler.transform(Xva)\n",
    "        for l1 in l1_ratio_list:\n",
    "            for alpha in alpha_grid:\n",
    "                model = CoxnetSurvivalAnalysis(l1_ratio=l1, alphas=[alpha], max_iter=10000, tol=1e-6)\n",
    "                try:\n",
    "                    model.fit(Xtr_std, ytr)\n",
    "                    beta = np.asarray(model.coef_, dtype=float).ravel()\n",
    "                    risk_va = np.dot(Xva_std, beta)\n",
    "                    cidx = concordance_index_censored(yva[\"event\"], yva[\"time\"], risk_va)[0]\n",
    "                    alpha_scores.setdefault((l1, float(alpha)), []).append(float(cidx))\n",
    "                except (ArithmeticError, FloatingPointError) as err:\n",
    "                    print(f\"[CV] Skipping l1={l1}, alpha={alpha:.3g}: {type(err).__name__}: {err}\")\n",
    "                    continue\n",
    "\n",
    "        print(f\"  Fold {fold}/{n_splits} done\")\n",
    "\n",
    "    stats = []\n",
    "    for (l1, a), vals in alpha_scores.items():\n",
    "        m = float(np.mean(vals)); s = float(np.std(vals, ddof=1)) if len(vals) > 1 else 0.0\n",
    "        stats.append((l1, a, m, s))\n",
    "\n",
    "    best_row = max(stats, key=lambda z: z[2])\n",
    "    best_mean, best_sd = best_row[2], best_row[3]\n",
    "    threshold = best_mean - best_sd\n",
    "    print(f\"CV best mean C={best_mean:.3f}, SD={best_sd:.3f} -> One-SE threshold={threshold:.3f}\")\n",
    "\n",
    "    # Prefer l1=1.0 if within one-SE, then lower alphas\n",
    "    stats_sorted = sorted(stats, key=lambda z: (z[0] != 1.0, z[1]))  # l1=1.0 first, then alpha ascending\n",
    "    candidate = None\n",
    "    for l1, a, m, s in stats_sorted:\n",
    "        if m >= threshold:\n",
    "            candidate = (l1, a, m, s)\n",
    "            break  # <- pick the first (smallest alpha) within One-SE\n",
    "    # fallback if nothing met the threshold\n",
    "    if candidate is None:\n",
    "        candidate = max(stats, key=lambda z: z[2])  # best mean CV\n",
    "    l1_sel, alpha_sel, mean_sel, sd_sel = candidate\n",
    "\n",
    "    print(f\"Selected: l1={l1_sel:.2f}, alpha={alpha_sel:.4g}, CV mean={mean_sel:.3f} (±{sd_sel:.3f})\")\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xtr_std = scaler.fit_transform(X_train)\n",
    "    model = CoxnetSurvivalAnalysis(l1_ratio=l1_sel, alphas=[alpha_sel], max_iter=10000, tol=1e-6)\n",
    "    model.fit(Xtr_std, y_train)\n",
    "    beta = np.asarray(model.coef_, dtype=float).ravel()\n",
    "    nz = int((np.abs(beta) > 1e-12).sum())\n",
    "    if nz == 0:\n",
    "        # fallback to the best mean-CV (not One-SE) solution\n",
    "        best_l1, best_a, _, _ = max(stats, key=lambda z: z[2])\n",
    "        model = CoxnetSurvivalAnalysis(l1_ratio=best_l1, alphas=[best_a], max_iter=10000, tol=1e-6)\n",
    "        model.fit(Xtr_std, y_train)\n",
    "        beta = np.asarray(model.coef_, dtype=float).ravel()\n",
    "        nz = int((np.abs(beta) > 1e-12).sum())\n",
    "    print(f\"Final refit: non-zero features = {nz}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"l1_ratio\": l1_sel,\n",
    "        \"alpha\": float(alpha_sel),\n",
    "        \"beta\": beta,\n",
    "        \"scaler\": scaler,\n",
    "        \"cv_cindex_mean\": float(mean_sel),\n",
    "        \"cv_cindex_sd\": float(sd_sel),\n",
    "    }\n",
    "\n",
    "def save_placeholder_km(times, events, risk_scores, out_png, title, reason):\n",
    "    \"\"\"Create a PNG explaining why KM-by-risk wasn’t plotted.\"\"\"\n",
    "    n = len(times)\n",
    "    ev = int(np.sum(events))\n",
    "    rstd = float(np.nanstd(risk_scores))\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.axis(\"off\")\n",
    "    msg = (\n",
    "        f\"{title}\\n\\n\"\n",
    "        f\"KM by risk quantiles not generated.\\n\"\n",
    "        f\"Reason: {reason}\\n\\n\"\n",
    "        f\"N={n}, events={ev}\\n\"\n",
    "        f\"Risk std = {rstd:.3e}\"\n",
    "    )\n",
    "    plt.text(0.02, 0.98, msg, ha=\"left\", va=\"top\", wrap=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_coxnet(best, Xtr, ytr, Xte, yte, label, outdir):\n",
    "    t0 = time.perf_counter()\n",
    "    scaler = best[\"scaler\"]\n",
    "    beta = best[\"beta\"]\n",
    "    Xtr_std = scaler.transform(Xtr)\n",
    "    Xte_std = scaler.transform(Xte)\n",
    "\n",
    "    # risk = Xβ (larger = higher risk)\n",
    "    risk_te = np.dot(Xte_std, beta)\n",
    "\n",
    "    # Metrics\n",
    "    cidx = concordance_index_censored(yte[\"event\"], yte[\"time\"], risk_te)[0]\n",
    "    auc12 = auc24 = auc36 = np.nan\n",
    "    safe_t = _safe_auc_times(yte[\"time\"], [12, 24, 36])\n",
    "    if safe_t.size > 0:\n",
    "        aucs, _ = cumulative_dynamic_auc(ytr, yte, risk_te, times=safe_t)\n",
    "        for t_val, a in zip(safe_t, aucs):\n",
    "            if np.isclose(t_val, 12): auc12 = float(a)\n",
    "            if np.isclose(t_val, 24): auc24 = float(a)\n",
    "            if np.isclose(t_val, 36): auc36 = float(a)\n",
    "\n",
    "    # Coefs\n",
    "    sel_mask = np.abs(beta) > 1e-12\n",
    "    sel_cols = Xtr.columns[sel_mask]\n",
    "    coef_path = os.path.join(outdir, f\"{label}_nonzero_coeffs.csv\")\n",
    "    pd.Series(beta[sel_mask], index=sel_cols).sort_values(key=lambda s: np.abs(s), ascending=False)\\\n",
    "      .to_csv(coef_path, header=[\"coef\"])\n",
    "\n",
    "    # KM plot (always save a PNG)\n",
    "    km_path = os.path.join(outdir, f\"km_by_risk_tertiles_{label}.png\")\n",
    "    risk_std = float(np.nanstd(risk_te))\n",
    "    if risk_std < 1e-12 or pd.Series(risk_te).nunique(dropna=True) < 2:\n",
    "        reason = f\"constant/near-constant risk (std={risk_std:.2e}, non-zero coefs={int(sel_mask.sum())})\"\n",
    "        save_placeholder_km(yte[\"time\"], yte[\"event\"].astype(int), risk_te, km_path,\n",
    "                            f\"Kaplan–Meier by risk quantiles ({label}, test set)\", reason)\n",
    "        print(f\"[KM] Placeholder saved -> {km_path}\")\n",
    "    else:\n",
    "        km_plot_by_tertiles(yte[\"time\"], yte[\"event\"].astype(int), risk_te,\n",
    "                            km_path, f\"Kaplan–Meier by risk quantiles ({label}, test set)\")\n",
    "        print(f\"[KM] KM saved -> {km_path}\")\n",
    "\n",
    "    print(f\"{label}: C={cidx:.3f}, AUC@12/24/36=({auc12:.3f}, {auc24:.3f}, {auc36:.3f}), \"\n",
    "          f\"non-zero={len(sel_cols)}, saved coefs={coef_path}, KM={km_path} | {time.perf_counter()-t0:.2f}s\")\n",
    "\n",
    "    return risk_te, tidy_metric_row(\n",
    "        label, float(cidx), float(auc12), float(auc24), float(auc36),\n",
    "        note=f\"l1={best['l1_ratio']:.2f}; alpha={best['alpha']:.4g}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def basic_clean(df, X_clin, X_mir):\n",
    "    \"\"\"Small but useful extra cleaning (no imputation here).\"\"\"\n",
    "    # 1) Deduplicate on 'title'\n",
    "    if \"title\" in df.columns:\n",
    "        before = len(df)\n",
    "        df = df.drop_duplicates(subset=[\"title\"], keep=\"first\").reset_index(drop=True)\n",
    "        if len(df) != before:\n",
    "            print(f\"[CLEAN] Dropped {before-len(df)} duplicate rows by 'title'.\")\n",
    "\n",
    "    # 2) SEX values sanity (anything not 'male' -> 0 already encoded)\n",
    "    X_clin = X_clin.copy()\n",
    "    if \"Sex\" in X_clin.columns:\n",
    "        bad = set(df[\"Sex\"].astype(str).str.lower()) - {\"male\", \"female\", \"f\", \"m\", \"nan\"}\n",
    "        if bad:\n",
    "            print(f\"[CLEAN] Unusual Sex values found: {bad} (treated as not-male=0).\")\n",
    "\n",
    "    # 3) APOE4 should be 0/1/2\n",
    "    if \"apoe4\" in X_clin.columns:\n",
    "        clip_before = X_clin[\"apoe4\"].copy()\n",
    "        X_clin[\"apoe4\"] = pd.to_numeric(X_clin[\"apoe4\"], errors=\"coerce\").clip(lower=0, upper=2)\n",
    "        if not np.allclose(clip_before, X_clin[\"apoe4\"], equal_nan=True):\n",
    "            print(\"[CLEAN] Clipped APOE4 to 0..2.\")\n",
    "\n",
    "    # 4) Age sanity (flag, don’t drop)\n",
    "    if \"Age\" in X_clin.columns:\n",
    "        oob = ((X_clin[\"Age\"] < 40) | (X_clin[\"Age\"] > 100)).sum()\n",
    "        if oob:\n",
    "            print(f\"[CLEAN] {oob} Age values outside [40,100] — kept but flagged.\")\n",
    "\n",
    "    # 5) Drop constant miRNAs\n",
    "    X_mir = X_mir.copy()\n",
    "    const_cols = X_mir.columns[X_mir.nunique(dropna=True) <= 1].tolist()\n",
    "    if const_cols:\n",
    "        X_mir = X_mir.drop(columns=const_cols)\n",
    "        print(f\"[CLEAN] Dropped {len(const_cols)} constant miRNAs.\")\n",
    "\n",
    "    return df, X_clin, X_mir\n",
    "\n",
    "def quick_eda(df, X_clin, X_mir, time_months, event, outdir):\n",
    "    \"\"\"Save compact EDA artifacts to outputs/\"\"\"\n",
    "    # Missingness report\n",
    "    miss = df.isna().mean().sort_values(ascending=False).to_frame(\"missing_frac\")\n",
    "    miss.to_csv(os.path.join(outdir, \"eda_missingness.csv\"))\n",
    "\n",
    "    # Event/censoring summary\n",
    "    n = len(event); ev = int(np.sum(event)); rate = ev / n\n",
    "    pd.DataFrame({\"n\":[n], \"events\":[ev], \"event_rate\":[rate]}).to_csv(\n",
    "        os.path.join(outdir, \"eda_survival_summary.csv\"), index=False\n",
    "    )\n",
    "\n",
    "    # Clinical summary\n",
    "    clin_desc = X_clin.describe(include=\"all\").T\n",
    "    clin_desc.to_csv(os.path.join(outdir, \"eda_clinical_describe.csv\"))\n",
    "\n",
    "    # Simple histograms\n",
    "    plt.figure(); X_clin[\"Age\"].hist(bins=20); plt.title(\"Age\"); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"eda_hist_age.png\"), dpi=120); plt.close()\n",
    "\n",
    "    plt.figure(); pd.Series(time_months).hist(bins=20)\n",
    "    plt.title(\"Follow-up time (months)\"); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, \"eda_hist_time.png\"), dpi=120); plt.close()\n",
    "\n",
    "    # miRNA quick checks\n",
    "    nunique = X_mir.nunique().describe()\n",
    "    nunique.to_csv(os.path.join(outdir, \"eda_mirna_nunique_summary.csv\"))\n",
    "    print(f\"[EDA] Saved basic EDA CSVs/plots to {os.path.abspath(outdir)}\")\n",
    "\n",
    "# ----- Train-only imputers (prevent leakage)\n",
    "def fit_imputers(Xc_tr: pd.DataFrame, Xm_tr: pd.DataFrame):\n",
    "    imp_clin = SimpleImputer(strategy=\"median\")\n",
    "    imp_mir  = SimpleImputer(strategy=\"median\")\n",
    "    imp_clin.fit(Xc_tr)\n",
    "    imp_mir.fit(Xm_tr)\n",
    "    return imp_clin, imp_mir\n",
    "\n",
    "def apply_imputers(imp_clin, imp_mir, Xc_df: pd.DataFrame, Xm_df: pd.DataFrame):\n",
    "    Xc = pd.DataFrame(imp_clin.transform(Xc_df), columns=Xc_df.columns)\n",
    "    Xm = pd.DataFrame(imp_mir.transform(Xm_df), columns=Xm_df.columns)\n",
    "    return Xc, Xm\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Optional RSF\n",
    "# ---------------------------\n",
    "def fit_eval_rsf(Xtr, ytr, Xte, yte, label, outdir):\n",
    "    rsf = RandomSurvivalForest(\n",
    "        n_estimators=500,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ).fit(Xtr, ytr)\n",
    "    risk_te = -rsf.predict(Xte)\n",
    "    cidx = concordance_index_censored(yte[\"event\"], yte[\"time\"], risk_te)[0]\n",
    "    aucs, _ = cumulative_dynamic_auc(ytr, yte, risk_te, times=np.array([12, 24, 36]))\n",
    "    auc12, auc24, auc36 = [float(x) for x in aucs]\n",
    "    km_plot_by_tertiles(yte[\"time\"], yte[\"event\"].astype(int), risk_te,\n",
    "                        os.path.join(outdir, f\"km_by_risk_tertiles_{label}.png\"),\n",
    "                        f\"Kaplan–Meier by risk tertile ({label}, test set)\")\n",
    "    return risk_te, tidy_metric_row(label, float(cidx), float(auc12), float(auc24), float(auc36))\n",
    "# ----- Safe time grid for time-dependent AUC\n",
    "def _safe_auc_times(test_times: np.ndarray, requested_times):\n",
    "    \"\"\"Return times within [min(test_times), max(test_times)) as a sorted float array.\"\"\"\n",
    "    req = np.asarray(requested_times, dtype=float)\n",
    "    tmin = float(np.min(test_times))\n",
    "    tmax = float(np.max(test_times)) - 1e-9  # open upper bound\n",
    "    ok = req[(req >= tmin) & (req < tmax)]\n",
    "    return np.unique(ok)\n",
    "\n",
    "\n",
    "# ----- Calibration & Brier/IBS helpers\n",
    "def calibration_slope_on_test(cph_model, X_test, t_test, e_test):\n",
    "    # Linear predictor from TRAINED model on TEST\n",
    "    lp = cph_model.predict_partial_hazard(X_test).to_numpy().ravel()\n",
    "    df = pd.DataFrame({\"time\": t_test, \"event\": e_test, \"lp\": lp})\n",
    "    cal = CoxPHFitter()\n",
    "    cal.fit(df, duration_col=\"time\", event_col=\"event\")\n",
    "    slope = float(cal.params_[\"lp\"])\n",
    "    return slope\n",
    "\n",
    "def brier_and_ibs_clinical(cph_model, X_train, t_tr, e_tr, X_test, t_te, e_te, times_months):\n",
    "    \"\"\"\n",
    "    Compute Brier scores at requested times, plus IBS on a safe grid that lies strictly\n",
    "    within the test set follow-up interval [min(test_time), max(test_time)).\n",
    "\n",
    "    Returns: dict like {\"ibs\": float, \"brier_12m\": ..., \"brier_24m\": ..., ...}\n",
    "             If a requested time is outside the valid window, its brier_* value is NaN.\n",
    "    \"\"\"\n",
    "    if not SKSURV_OK:\n",
    "        return {\"ibs\": np.nan, **{f\"brier_{int(t)}m\": np.nan for t in np.asarray(times_months, dtype=float)}}\n",
    "\n",
    "    # survival objects\n",
    "    y_tr = to_surv(t_tr, e_tr)\n",
    "    y_te = to_surv(t_te, e_te)\n",
    "\n",
    "    # Test-time window (max is open interval)\n",
    "    tmin_test = float(np.min(t_te))\n",
    "    tmax_test = float(np.max(t_te))\n",
    "    eps = 1e-6  # keep IBS grid strictly inside [tmin, tmax)\n",
    "\n",
    "    # ---------- Discrete Brier scores at requested times ----------\n",
    "    req_times = np.asarray(times_months, dtype=float)\n",
    "    # keep only times in [tmin_test, tmax_test)\n",
    "    disc_times = req_times[(req_times >= tmin_test) & (req_times < tmax_test)]\n",
    "\n",
    "    brier_map = {}\n",
    "    if disc_times.size > 0:\n",
    "        # lifelines → survival prob matrix: (n_samples x n_times)\n",
    "        sf_disc = cph_model.predict_survival_function(X_test, times=disc_times).T.values\n",
    "        # Handle sksurv version differences: sometimes returns (times, scores)\n",
    "        res = sk_brier_score(y_tr, y_te, sf_disc, times=disc_times)\n",
    "        if isinstance(res, tuple):\n",
    "            first, second = res[:2]\n",
    "            first = np.asarray(first, dtype=float)\n",
    "            second = np.asarray(second, dtype=float)\n",
    "            briers = second if (first.shape == disc_times.shape and np.allclose(first, disc_times)) else first\n",
    "        else:\n",
    "            briers = np.asarray(res, dtype=float)\n",
    "\n",
    "        # map back to requested keys, NaN for out-of-range requests\n",
    "        for t in req_times:\n",
    "            key = f\"brier_{int(t)}m\"\n",
    "            if np.any(np.isclose(disc_times, t)):\n",
    "                idx = int(np.where(np.isclose(disc_times, t))[0][0])\n",
    "                brier_map[key] = float(briers[idx])\n",
    "            else:\n",
    "                brier_map[key] = float(\"nan\")\n",
    "    else:\n",
    "        # All requested times are out of range\n",
    "        brier_map = {f\"brier_{int(t)}m\": float(\"nan\") for t in req_times}\n",
    "\n",
    "    # ---------- IBS on a safe grid ----------\n",
    "    # Choose a start ≥ max(tmin_test + eps, smallest valid requested time if any)\n",
    "    start_ib = max(tmin_test + eps, float(np.min(disc_times)) if disc_times.size > 0 else tmin_test + eps)\n",
    "    # Choose an end  ≤ min(tmax_test - eps, largest valid requested time if any)\n",
    "    end_ib = min(tmax_test - eps, float(np.max(disc_times)) if disc_times.size > 0 else tmax_test - eps)\n",
    "\n",
    "    # Fallback if bounds are degenerate (very short follow-up ranges)\n",
    "    if not (end_ib > start_ib):\n",
    "        span = max(tmax_test - tmin_test, 1.0)\n",
    "        start_ib = tmin_test + 0.1 * span\n",
    "        end_ib   = tmin_test + 0.9 * span\n",
    "\n",
    "    # If still degenerate, give up gracefully\n",
    "    if not (end_ib > start_ib):\n",
    "        ibs_val = float(\"nan\")\n",
    "    else:\n",
    "        times_ibs = np.linspace(start_ib, end_ib, 60)\n",
    "        sf_ibs = cph_model.predict_survival_function(X_test, times=times_ibs).T.values\n",
    "        ibs_val = float(integrated_brier_score(y_tr, y_te, sf_ibs, times=times_ibs))\n",
    "\n",
    "    return {\"ibs\": ibs_val, **brier_map}\n",
    "\n",
    "\n",
    "def refit_coxph_for_survival(Xtr_sel, t_tr, e_tr, penalizer=0.1):\n",
    "    df = pd.concat([pd.DataFrame({\"time\": t_tr, \"event\": e_tr}), Xtr_sel.reset_index(drop=True)], axis=1)\n",
    "    # small ridge penalty guards against singularities in high-dimensional refits\n",
    "    cph = CoxPHFitter(penalizer=penalizer)\n",
    "    cph.fit(df, duration_col=\"time\", event_col=\"event\")\n",
    "    return cph\n",
    "\n",
    "\n",
    "# ----- Bootstrap CIs (discrimination)\n",
    "def bootstrap_metric_cis(y_tr, y_te, risk, times=(12,24,36), n_boot=500, seed=123):\n",
    "    if not SKSURV_OK:\n",
    "        return {}\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = len(y_te[\"time\"])\n",
    "\n",
    "    # Use only times that are inside the full test window\n",
    "    global_safe = _safe_auc_times(y_te[\"time\"], times)\n",
    "    # Prepare collectors per-time\n",
    "    auc_vals = {t: [] for t in global_safe}\n",
    "    c_vals = []\n",
    "\n",
    "    idx_all = np.arange(n)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(idx_all, size=n, replace=True)\n",
    "        # Subset test via Surv re-construction\n",
    "        yte_b = Surv.from_arrays(event=y_te[\"event\"][idx], time=y_te[\"time\"][idx])\n",
    "        risk_b = risk[idx]\n",
    "\n",
    "        # C-index (doesn't depend on times)\n",
    "        c_vals.append(concordance_index_censored(yte_b[\"event\"], yte_b[\"time\"], risk_b)[0])\n",
    "\n",
    "        # For this bootstrap, further restrict to times inside the bootstrap window\n",
    "        safe_iter = _safe_auc_times(yte_b[\"time\"], global_safe)\n",
    "        if safe_iter.size == 0:\n",
    "            continue\n",
    "        aucs, _ = cumulative_dynamic_auc(y_tr, yte_b, risk_b, times=safe_iter)\n",
    "        for t_val, a in zip(safe_iter, aucs):\n",
    "            auc_vals[t_val].append(float(a))\n",
    "\n",
    "    def ci(a_list):\n",
    "        if len(a_list) == 0:\n",
    "            return (float(\"nan\"), float(\"nan\"))\n",
    "        lo, hi = np.percentile(a_list, [2.5, 97.5])\n",
    "        return float(lo), float(hi)\n",
    "\n",
    "    out = {\"cindex_ci\": ci(c_vals)}\n",
    "    # Only report CIs for times that were computed at least once\n",
    "    for t in times:\n",
    "        if t in auc_vals:\n",
    "            out[f\"auc_{int(t)}m_ci\"] = ci(auc_vals[t])\n",
    "        else:\n",
    "            out[f\"auc_{int(t)}m_ci\"] = (float(\"nan\"), float(\"nan\"))\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----- Decision Curve Analysis\n",
    "def predict_event_prob_by_time_cph(cph_model, X, t_months):\n",
    "    # 1 - S_i(t)\n",
    "    sf = cph_model.predict_survival_function(X, times=[t_months])  # DataFrame (times x n)\n",
    "    return 1.0 - sf.T.values.ravel()\n",
    "\n",
    "def decision_curve_net_benefit(e_time, e_event, p_event, thresholds, horizon_months):\n",
    "    \"\"\"\n",
    "    Approximate DCA at a fixed horizon.\n",
    "    Use only subjects with observed time >= horizon or who converted before horizon.\n",
    "    \"\"\"\n",
    "    mask = (e_time >= horizon_months) | ((e_time < horizon_months) & (e_event == 1))\n",
    "    y = ((e_time < horizon_months) & (e_event == 1))[mask].astype(int)\n",
    "    p = p_event[mask]\n",
    "    N = len(y); out = []\n",
    "    for pt in thresholds:\n",
    "        pred = (p >= pt).astype(int)\n",
    "        TP = (pred * y).sum(); FP = (pred * (1 - y)).sum()\n",
    "        nb = (TP / N) - (FP / N) * (pt / (1 - pt))\n",
    "        # treat-all and treat-none\n",
    "        nb_all = (y.sum() / N) - (1 - (y.sum() / N)) * (pt / (1 - pt))\n",
    "        nb_none = 0.0\n",
    "        out.append((pt, nb, nb_all, nb_none))\n",
    "    return pd.DataFrame(out, columns=[\"threshold\", \"net_benefit\", \"treat_all\", \"treat_none\"])\n",
    "\n",
    "# ----- DCA plotting helpers -----\n",
    "def plot_dca(dca_df: pd.DataFrame, out_png: str, title: str):\n",
    "    plt.figure()\n",
    "    plt.plot(dca_df[\"threshold\"], dca_df[\"net_benefit\"], label=\"Model\")\n",
    "    plt.plot(dca_df[\"threshold\"], dca_df[\"treat_all\"], linestyle=\"--\", label=\"Treat-all\")\n",
    "    plt.plot(dca_df[\"threshold\"], dca_df[\"treat_none\"], linestyle=\"--\", label=\"Treat-none\")\n",
    "    plt.xlabel(\"Threshold probability @ 24 months\")\n",
    "    plt.ylabel(\"Net benefit\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_dca_compare(dcas: dict, out_png: str, title: str):\n",
    "    # dcas = {\"Label\": dca_df, ...}\n",
    "    plt.figure()\n",
    "    any_df = next(iter(dcas.values()))\n",
    "    for label, dca_df in dcas.items():\n",
    "        plt.plot(dca_df[\"threshold\"], dca_df[\"net_benefit\"], label=label)\n",
    "    # same treat-all/none across same horizon & labels; take from any_df\n",
    "    plt.plot(any_df[\"threshold\"], any_df[\"treat_all\"], linestyle=\"--\", label=\"Treat-all\")\n",
    "    plt.plot(any_df[\"threshold\"], any_df[\"treat_none\"], linestyle=\"--\", label=\"Treat-none\")\n",
    "    plt.xlabel(\"Threshold probability @ 24 months\")\n",
    "    plt.ylabel(\"Net benefit\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- NEW: simple calibration-at-24m (KM-based) ----------\n",
    "def calibration_curve_at_time(cph_model, X_test, t_test, e_test,\n",
    "                              t_months=24, n_bins=10, min_bin=None):\n",
    "    \"\"\"\n",
    "    Quantile-bin predicted event probabilities at t_months and compute\n",
    "    observed (1 - KM) per bin. Adaptive: reduces bins until each bin\n",
    "    has >= min_bin rows; falls back to 1 bin if needed.\n",
    "    \"\"\"\n",
    "    p = predict_event_prob_by_time_cph(cph_model, X_test, t_months)\n",
    "    df = pd.DataFrame({\"p\": p, \"time\": t_test, \"event\": e_test}).dropna(subset=[\"p\"])\n",
    "\n",
    "    N = len(df)\n",
    "    if N == 0:\n",
    "        return pd.DataFrame(columns=[\"pred_mean\", \"obs\", \"n\"])\n",
    "\n",
    "    # Sensible default for small test sets: about half the average bin size\n",
    "    if min_bin is None:\n",
    "        min_bin = max(3, int(np.ceil(N / max(2, n_bins) / 2)))\n",
    "\n",
    "    # Start with up to n_bins but not more than unique p’s\n",
    "    q = int(min(n_bins, max(2, df[\"p\"].nunique())))\n",
    "    bins_ok = False\n",
    "\n",
    "    while q >= 2:\n",
    "        try:\n",
    "            bins = pd.qcut(df[\"p\"], q=q, duplicates=\"drop\")\n",
    "        except Exception:\n",
    "            q -= 1\n",
    "            continue\n",
    "        df[\"bin\"] = bins\n",
    "        sizes = df[\"bin\"].value_counts()\n",
    "        if (sizes >= min_bin).all():\n",
    "            bins_ok = True\n",
    "            break\n",
    "        q -= 1\n",
    "\n",
    "    if not bins_ok:\n",
    "        # Fall back to a single bin with everything\n",
    "        df[\"bin\"] = 0\n",
    "\n",
    "    out = []\n",
    "    kmf = KaplanMeierFitter()\n",
    "    for _, sub in df.groupby(\"bin\"):\n",
    "        kmf.fit(sub[\"time\"].values, sub[\"event\"].values.astype(int))\n",
    "        s_t = float(kmf.predict(t_months))\n",
    "        out.append((float(sub[\"p\"].mean()), 1.0 - s_t, len(sub)))\n",
    "\n",
    "    return pd.DataFrame(out, columns=[\"pred_mean\", \"obs\", \"n\"]).sort_values(\"pred_mean\")\n",
    "\n",
    "\n",
    "def save_calibration_plot_and_csv(cph_model, X_test, t_test, e_test,\n",
    "                                  t_months, out_prefix, title,\n",
    "                                  n_bins=6, min_bin=None):\n",
    "    cur = calibration_curve_at_time(\n",
    "        cph_model, X_test, t_test, e_test,\n",
    "        t_months=t_months, n_bins=n_bins, min_bin=min_bin\n",
    "    )\n",
    "    csv_path = f\"{out_prefix}.csv\"\n",
    "    png_path = f\"{out_prefix}.png\"\n",
    "    cur.to_csv(csv_path, index=False)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(cur[\"pred_mean\"], cur[\"obs\"], s=30)\n",
    "    # 45-degree reference\n",
    "    plt.plot([0.0, 1.0], [0.0, 1.0], linestyle=\"--\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(f\"Predicted probability @ {t_months}m\")\n",
    "    plt.ylabel(f\"Observed probability @ {t_months}m (1 - KM)\")\n",
    "    plt.title(title + f\"  (bins={cur.shape[0]})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_path, dpi=150)\n",
    "    plt.close()\n",
    "    return csv_path, png_path\n",
    "\n",
    "\n",
    "# ---------- NEW: better Table 1 (train vs test) ----------\n",
    "def write_table1_train_test(df, tr_idx, te_idx, outdir):\n",
    "    \"\"\"\n",
    "    Creates train vs test descriptive table for Diagnosis, Age, Sex, APOE4, event rate, follow-up.\n",
    "    Saves to baseline_table1_train_test.csv\n",
    "    \"\"\"\n",
    "    base = df.loc[:, [\"Diagnosis\", \"Age\", \"Sex\", \"apoe4\", \"Day\"]].copy()\n",
    "    base[\"event\"] = (df[\"Diagnosis\"].astype(str) == \"MCI-C\").astype(int)\n",
    "    base[\"time_m\"] = pd.to_numeric(df[\"Day\"], errors=\"coerce\") / 30.44\n",
    "\n",
    "    def summarize(idx):\n",
    "        sub = base.iloc[idx]\n",
    "        return pd.Series({\n",
    "            \"n\": len(sub),\n",
    "            \"event_rate\": sub[\"event\"].mean(),\n",
    "            \"Age_mean\": pd.to_numeric(sub[\"Age\"], errors=\"coerce\").mean(),\n",
    "            \"Age_sd\": pd.to_numeric(sub[\"Age\"], errors=\"coerce\").std(),\n",
    "            \"Sex_male_pct\": (sub[\"Sex\"].astype(str).str.lower().eq(\"male\").mean()),\n",
    "            \"APOE4_mean\": pd.to_numeric(sub[\"apoe4\"], errors=\"coerce\").mean(),\n",
    "            \"time_m_mean\": sub[\"time_m\"].mean(),\n",
    "            \"time_m_sd\": sub[\"time_m\"].std(),\n",
    "        })\n",
    "\n",
    "    tbl = pd.concat({\"Train\": summarize(tr_idx), \"Test\": summarize(te_idx)}, axis=1)\n",
    "    out_path = os.path.join(outdir, \"baseline_table1_train_test.csv\")\n",
    "    tbl.to_csv(out_path)\n",
    "    return out_path\n",
    "\n",
    "# ---------- NEW: bootstrap CIs for penalized models too ----------\n",
    "def add_bootstrap_cis_to_metrics(metrics_dict, y_tr, y_te, risk, times=(12,24,36), n_boot=300):\n",
    "    cis = bootstrap_metric_cis(y_tr, y_te, risk, times=times, n_boot=n_boot)\n",
    "    metrics_dict.update(cis)\n",
    "    return metrics_dict\n",
    "\n",
    "# ---------- NEW (optional): quick seed sweep for robustness ----------\n",
    "RUN_SEED_SWEEP = False  # set True to run\n",
    "SEED_SWEEP_LIST = [101, 202, 303, 404, 505]\n",
    "\n",
    "def seed_sweep_summary(csv_path, outdir, seeds=SEED_SWEEP_LIST):\n",
    "    \"\"\"\n",
    "    Reruns only the clinical model across different seeds; summarizes mean±sd.\n",
    "    (Keeps it lightweight for the dissertation appendix.)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # NOTE: this is a placeholder stub if you later refactor main() into reusable pieces.\n",
    "    # For now, we just document the option; full refactor would call your modeling pieces per seed.\n",
    "    sweep_path = os.path.join(outdir, \"metrics_multi_seed_README.txt\")\n",
    "    with open(sweep_path, \"w\") as f:\n",
    "        f.write(\"Seed sweep placeholder. To enable, refactor main() into reusable steps and call them per seed.\\n\")\n",
    "    return sweep_path\n",
    "\n",
    "\n",
    "# ----- Subgroup metrics (fairness/robustness)\n",
    "def subgroup_metrics(y_tr, t_te, e_te, risk, groups: pd.Series, label_prefix, times=(12,24,36)):\n",
    "    rows = []\n",
    "    # groups.groupby(groups).groups returns dict: value -> index positions\n",
    "    for gval, idx_list in groups.groupby(groups).groups.items():\n",
    "        idx = np.array(list(idx_list), dtype=int)\n",
    "        yte_g = Surv.from_arrays(event=(e_te[idx].astype(bool)), time=t_te[idx].astype(float))\n",
    "        r_g = risk[idx]\n",
    "        c = concordance_index_censored(yte_g[\"event\"], yte_g[\"time\"], r_g)[0]\n",
    "        aucs, _ = cumulative_dynamic_auc(y_tr, yte_g, r_g, times=np.array(times))\n",
    "        rows.append({\n",
    "            \"group_var\": label_prefix, \"group\": gval,\n",
    "            \"n\": int(len(idx)), \"cindex\": float(c),\n",
    "            **{f\"auc_{t}m\": float(a) for t, a in zip(times, aucs)}\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Orchestrator\n",
    "# ---------------------------\n",
    "def main(csv_path=\"workingTransposed.csv\", outdir=\"outputs\", seed=123, test_frac=0.25, try_rsf=False):\n",
    "    np.random.seed(seed)\n",
    "    ensure_dir(outdir)\n",
    "    print(\"\\n== RUN CONFIG ==\")\n",
    "    print(\"csv_path:\", csv_path)\n",
    "    print(\"outdir:\", os.path.abspath(outdir))\n",
    "    print(\"ENABLE_PENALIZED:\", ENABLE_PENALIZED)\n",
    "\n",
    "    # 1) Load & audit\n",
    "    df, ids, time_months, event, X_clin, X_mir = load_dataset(csv_path)\n",
    "    df, X_clin, X_mir = basic_clean(df, X_clin, X_mir)\n",
    "    quick_eda(df, X_clin, X_mir, time_months, event, outdir)\n",
    "\n",
    "    # 2) Split (stratified)\n",
    "    print(\"\\n== STEP 2/6: Train/Test split ==\")\n",
    "    tr_idx, te_idx = stratified_split(event, test_size=test_frac, seed=seed)\n",
    "    print(f\"Train n={len(tr_idx)}, Test n={len(te_idx)} | Test events={event[te_idx].sum()} ({event[te_idx].mean():.1%})\")\n",
    "    # NEW: nicely formatted Table 1 (train vs test)\n",
    "    write_table1_train_test(df, tr_idx, te_idx, outdir)\n",
    "\n",
    "\n",
    "    # 3) Slice folds\n",
    "    Xc_tr, Xc_te = X_clin.iloc[tr_idx].reset_index(drop=True), X_clin.iloc[te_idx].reset_index(drop=True)\n",
    "    Xm_tr, Xm_te = X_mir.iloc[tr_idx].reset_index(drop=True), X_mir.iloc[te_idx].reset_index(drop=True)\n",
    "    t_tr, t_te = time_months[tr_idx], time_months[te_idx]\n",
    "    e_tr, e_te = event[tr_idx], event[te_idx]\n",
    "\n",
    "    # Baseline table\n",
    "    base = df.loc[:, [\"Diagnosis\", \"Age\", \"Sex\", \"apoe4\"]].copy()\n",
    "    base[\"time_months\"] = time_months\n",
    "    base.to_csv(os.path.join(outdir, \"baseline_table_raw.csv\"), index=False)\n",
    "\n",
    "    # --- Baseline summaries (overall, by outcome, by split) ---\n",
    "    # Types & cleaning for summaries\n",
    "    base_s = base.copy()\n",
    "    base_s[\"Diagnosis\"] = base_s[\"Diagnosis\"].astype(str)\n",
    "    base_s[\"Sex\"] = base_s[\"Sex\"].astype(str)\n",
    "    for c in [\"Age\", \"apoe4\", \"time_months\"]:\n",
    "        base_s[c] = pd.to_numeric(base_s[c], errors=\"coerce\")\n",
    "    \n",
    "    num_cols = [\"Age\", \"apoe4\", \"time_months\"]\n",
    "    cat_cols = [\"Diagnosis\", \"Sex\"]\n",
    "    \n",
    "    # 1) Overall numeric summary\n",
    "    overall_num = (\n",
    "        base_s[num_cols]\n",
    "          .agg(['count', 'mean', 'std', 'median', 'min', 'max'])\n",
    "          .T.round(3)\n",
    "    )\n",
    "    overall_num.index.name = \"variable\"\n",
    "\n",
    "    \n",
    "    # 2) Overall categorical counts + %\n",
    "    overall_cat_list = []\n",
    "    for col in cat_cols:\n",
    "        vc = base_s[col].value_counts(dropna=False)\n",
    "        pct = (vc / vc.sum() * 100).round(1).astype(str) + \"%\"\n",
    "        tmp = pd.DataFrame({\"variable\": col, \"level\": vc.index.astype(str),\n",
    "                            \"count\": vc.values, \"percent\": pct.values})\n",
    "        overall_cat_list.append(tmp)\n",
    "    overall_cat = pd.concat(overall_cat_list, ignore_index=True)\n",
    "    \n",
    "    # 3) By outcome (Diagnosis) numeric summary + Mann–Whitney p-values\n",
    "    by_dx = base_s.groupby(\"Diagnosis\")[num_cols].agg(\n",
    "        [\"count\", \"mean\", \"std\", \"median\"]\n",
    "    ).round(3)\n",
    "    by_dx.columns = [f\"{v}_{stat}\" for v, stat in by_dx.columns]\n",
    "    by_dx.index.name = \"Diagnosis\"\n",
    "    \n",
    "    # p-values (two-sided Mann–Whitney U for robustness)\n",
    "    try:\n",
    "        from scipy import stats\n",
    "        dx_vals = base_s[\"Diagnosis\"].dropna().unique().tolist()\n",
    "        if len(dx_vals) == 2:\n",
    "            g1, g2 = dx_vals[0], dx_vals[1]\n",
    "            p_rows = []\n",
    "            for v in num_cols:\n",
    "                a = base_s.loc[base_s[\"Diagnosis\"] == g1, v].dropna()\n",
    "                b = base_s.loc[base_s[\"Diagnosis\"] == g2, v].dropna()\n",
    "                if len(a) > 0 and len(b) > 0:\n",
    "                    p = float(stats.mannwhitneyu(a, b, alternative=\"two-sided\").pvalue)\n",
    "                else:\n",
    "                    p = float(\"nan\")\n",
    "                p_rows.append({\"variable\": v, \"p_mannwhitney\": p})\n",
    "            p_df = pd.DataFrame(p_rows).set_index(\"variable\")\n",
    "        else:\n",
    "            p_df = pd.DataFrame(index=num_cols, data={\"p_mannwhitney\": float(\"nan\")})\n",
    "    except Exception:\n",
    "        p_df = pd.DataFrame(index=num_cols, data={\"p_mannwhitney\": float(\"nan\")})\n",
    "    \n",
    "    # Flatten by_dx to a friendly table and join p-values\n",
    "    by_dx_num = by_dx.reset_index()\n",
    "    by_dx_p = p_df.reset_index().rename(columns={\"index\": \"variable\"})\n",
    "    # Make a wide numeric table with p-values appended per variable\n",
    "    outcome_levels = base_s[\"Diagnosis\"].dropna().unique().tolist()\n",
    "    # If exactly 2 groups, rename columns for clarity\n",
    "    if len(outcome_levels) == 2:\n",
    "        a, b = outcome_levels\n",
    "        rename_map = {\n",
    "            f\"{v}_mean\": f\"{v}_mean__{a}\" for v in num_cols\n",
    "        } | {\n",
    "            f\"{v}_std\": f\"{v}_std__{a}\" for v in num_cols\n",
    "        }\n",
    "        # Build per-group means/stds columns for both groups\n",
    "    # Instead of complex pivoting, emit a tidy long numeric table:\n",
    "    tidy_by_dx = (\n",
    "        base_s.melt(id_vars=[\"Diagnosis\"], value_vars=num_cols, var_name=\"variable\", value_name=\"value\")\n",
    "               .groupby([\"variable\", \"Diagnosis\"])[\"value\"]\n",
    "               .agg(count=\"count\", mean=\"mean\", std=\"std\", median=\"median\").round(3)\n",
    "               .reset_index()\n",
    "    )\n",
    "    \n",
    "    # 4) By split (train/test) — add a split label using indices from the split above\n",
    "    split_lab = pd.Series(index=base_s.index, dtype=\"object\")\n",
    "    split_lab.iloc[tr_idx] = \"train\"\n",
    "    split_lab.iloc[te_idx] = \"test\"\n",
    "    base_s[\"split\"] = split_lab.values\n",
    "    \n",
    "    by_split_num = (\n",
    "        base_s.groupby(\"split\")[num_cols]\n",
    "          .agg(['count', 'mean', 'std', 'median'])\n",
    "          .round(3)\n",
    "    )\n",
    "    by_split_num.index.name = \"split\"\n",
    "\n",
    "    \n",
    "    by_split_cat_list = []\n",
    "    for col in cat_cols:\n",
    "        vc = base_s.groupby(\"split\")[col].value_counts(dropna=False)\n",
    "        # convert to dataframe and add percentage within split\n",
    "        tmp = vc.rename(\"count\").reset_index()\n",
    "        tmp[\"percent\"] = (\n",
    "            tmp.groupby(\"split\")[\"count\"].transform(lambda x: (x / x.sum() * 100).round(1).astype(str) + \"%\")\n",
    "        )\n",
    "        tmp.insert(1, \"variable\", col)\n",
    "        by_split_cat_list.append(tmp)\n",
    "    by_split_cat = pd.concat(by_split_cat_list, ignore_index=True)\n",
    "    \n",
    "    # 5) Categorical association (Sex vs Diagnosis): χ² or Fisher’s exact when 2×2\n",
    "    try:\n",
    "        from scipy import stats\n",
    "        sex_tab = pd.crosstab(base_s[\"Diagnosis\"], base_s[\"Sex\"])\n",
    "        if sex_tab.shape == (2, 2):\n",
    "            fisher_p = float(stats.fisher_exact(sex_tab)[1])\n",
    "            cat_p = pd.DataFrame({\"test\": [\"Fisher_exact\"], \"p_value\": [fisher_p]})\n",
    "        else:\n",
    "            chi2, p, _, _ = stats.chi2_contingency(sex_tab)\n",
    "            cat_p = pd.DataFrame({\"test\": [\"Chi2\"], \"p_value\": [float(p)]})\n",
    "    except Exception:\n",
    "        cat_p = pd.DataFrame({\"test\": [\"NA\"], \"p_value\": [float(\"nan\")]})\n",
    "    \n",
    "    # Write all summaries\n",
    "    overall_num.to_csv(os.path.join(outdir, \"baseline_summary_overall_numeric.csv\"))\n",
    "    overall_cat.to_csv(os.path.join(outdir, \"baseline_summary_overall_categorical.csv\"), index=False)\n",
    "    tidy_by_dx.to_csv(os.path.join(outdir, \"baseline_summary_by_outcome_numeric_tidy.csv\"), index=False)\n",
    "    by_split_num.to_csv(os.path.join(outdir, \"baseline_summary_by_split_numeric.csv\"))\n",
    "    by_split_cat.to_csv(os.path.join(outdir, \"baseline_summary_by_split_categorical.csv\"), index=False)\n",
    "    cat_p.to_csv(os.path.join(outdir, \"baseline_sex_vs_diagnosis_pvalue.csv\"), index=False)\n",
    "    print(\"[Baseline] Wrote summary CSVs to:\", os.path.abspath(outdir))\n",
    "\n",
    "    # 4) Train-only imputation (prevents leakage) — must happen BEFORE modeling\n",
    "    imp_clin, imp_mir = fit_imputers(Xc_tr, Xm_tr)\n",
    "    Xc_tr, Xm_tr = apply_imputers(imp_clin, imp_mir, Xc_tr, Xm_tr)\n",
    "    Xc_te, Xm_te = apply_imputers(imp_clin, imp_mir, Xc_te, Xm_te)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    # 5) Clinical-only Cox\n",
    "    cph, risk_clin_te, met = fit_evaluate_clinical_cox(Xc_tr, t_tr, e_tr, Xc_te, t_te, e_te, outdir)\n",
    "\n",
    "    # Calibration & Brier/IBS for clinical\n",
    "    cal_slope = calibration_slope_on_test(cph, Xc_te, t_te, e_te)\n",
    "    brier_dict = brier_and_ibs_clinical(cph, Xc_tr, t_tr, e_tr, Xc_te, t_te, e_te, times_months=np.array([12,24,36]))\n",
    "    met.update({\"cal_slope\": cal_slope, **brier_dict})\n",
    "\n",
    "    # Bootstrap CIs (discrimination) — after risk is available\n",
    "    if SKSURV_OK:\n",
    "        y_tr_surv = to_surv(t_tr, e_tr)\n",
    "        y_te_surv = to_surv(t_te, e_te)\n",
    "        cis = bootstrap_metric_cis(y_tr_surv, y_te_surv, risk_clin_te, times=(12,24,36), n_boot=300)\n",
    "        met.update(cis)\n",
    "\n",
    "    metrics.append(met)\n",
    "\n",
    "    # 6) Decision Curve (24m) & subgroup metrics for clinical\n",
    "    p24 = predict_event_prob_by_time_cph(cph, Xc_te, t_months=24)\n",
    "    dca24 = decision_curve_net_benefit(t_te, e_te, p24, thresholds=np.linspace(0.05, 0.5, 10), horizon_months=24)\n",
    "    dca24.to_csv(os.path.join(outdir, \"dca_clinical_24m.csv\"), index=False)\n",
    "    plot_dca(dca24, os.path.join(outdir, \"dca_clinical_24m.png\"), \"Decision Curve — Clinical (24m)\")\n",
    "    # NEW: calibration curve @24m (clinical)\n",
    "    save_calibration_plot_and_csv(\n",
    "        cph, Xc_te, t_te, e_te, 24,\n",
    "        os.path.join(outdir, \"calibration_24m_clinical\"),\n",
    "        \"Calibration — Clinical @24m\",\n",
    "        n_bins=6\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    sub1 = subgroup_metrics(to_surv(t_tr, e_tr), t_te, e_te, risk_clin_te, Xc_te[\"Sex\"], \"Sex\")\n",
    "    sub2 = subgroup_metrics(to_surv(t_tr, e_tr), t_te, e_te, risk_clin_te,\n",
    "                            pd.Series((Xc_te[\"Age\"] > Xc_te[\"Age\"].median()).astype(int), index=Xc_te.index),\n",
    "                            \"AgeHigh\")\n",
    "    pd.concat([sub1, sub2]).to_csv(os.path.join(outdir, \"metrics_subgroups_clinical.csv\"), index=False)\n",
    "\n",
    "    # 7) Penalized blocks\n",
    "    if SKSURV_OK and ENABLE_PENALIZED:\n",
    "        try:\n",
    "            print(\"\\n== STEP 3/6: Prep survival objects ==\")\n",
    "            y_tr = to_surv(t_tr, e_tr)\n",
    "            y_te = to_surv(t_te, e_te)\n",
    "\n",
    "            print(\"\\n== STEP 4/6: Supervised screen + correlation prune (TRAIN ONLY) ==\")\n",
    "            sel_cols = univariate_screen(Xm_tr, y_tr, fdr=0.20, max_keep=100)\n",
    "            print(f\"After FDR screen: {len(sel_cols)} features\")\n",
    "            sel_cols = correlation_prune(Xm_tr[sel_cols], threshold=0.95)\n",
    "            print(f\"After correlation prune: {len(sel_cols)} features\")\n",
    "\n",
    "            Xm_tr_var = Xm_tr[sel_cols].reset_index(drop=True)\n",
    "            Xm_te_var = Xm_te[sel_cols].reset_index(drop=True)\n",
    "            pd.Series(sel_cols, name=\"selected_feature\").to_csv(\n",
    "                os.path.join(outdir, \"miRNA_screened_features.csv\"), index=False\n",
    "            )\n",
    "\n",
    "            print(\"\\n== STEP 5/6: Penalized Cox (miRNA-only, One-SE) ==\")\n",
    "            best_mir = fit_select_coxnet_innercv_onese(\n",
    "                Xm_tr_var, y_tr,\n",
    "                l1_ratio_list=(1.0, 0.5, 0.2),\n",
    "                alpha_grid=np.logspace(-1, 1.2, 30),\n",
    "                n_splits=5\n",
    "            )\n",
    "            risk_mir_te, met_mir = evaluate_coxnet(\n",
    "                best_mir, Xm_tr_var, y_tr, Xm_te_var, y_te, \"miRNA_coxnet\", outdir\n",
    "            )\n",
    "\n",
    "            # Refit standard CoxPH on selected miRNAs (for PH, calibration, Brier/IBS)\n",
    "            cph_mir = refit_coxph_for_survival(Xm_tr_var, t_tr, e_tr, penalizer=0.1)\n",
    "            cal_mir = calibration_slope_on_test(cph_mir, Xm_te_var, t_te, e_te)\n",
    "            brier_mir = brier_and_ibs_clinical(cph_mir, Xm_tr_var, t_tr, e_tr, Xm_te_var, t_te, e_te, np.array([12,24,36]))\n",
    "            met_mir.update({\"cal_slope\": cal_mir, **brier_mir})\n",
    "            # NEW: add bootstrap CIs for miRNA model\n",
    "            met_mir = add_bootstrap_cis_to_metrics(met_mir, y_tr, y_te, risk_mir_te, times=(12,24,36), n_boot=300)\n",
    "            \n",
    "            # NEW: calibration curve @24m (miRNA)\n",
    "            save_calibration_plot_and_csv(\n",
    "                cph_mir, Xm_te_var, t_te, e_te, 24,\n",
    "                os.path.join(outdir, \"calibration_24m_miRNA\"),\n",
    "                \"Calibration — miRNA-only @24m\",\n",
    "                n_bins=6\n",
    "            )\n",
    "\n",
    "\n",
    "            try:\n",
    "                cph_mir.check_assumptions(\n",
    "                    pd.concat([pd.DataFrame({\"time\": t_tr, \"event\": e_tr}), Xm_tr_var], axis=1),\n",
    "                    p_value_threshold=0.05, show_plots=False\n",
    "                )\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            metrics.append(met_mir)\n",
    "\n",
    "            print(\"\\n== STEP 6/6: Combined model (stack clinical LP only + miRNA) ==\")\n",
    "            clin_lp_tr = cph.predict_partial_hazard(Xc_tr).to_numpy().ravel()\n",
    "            clin_lp_te = cph.predict_partial_hazard(Xc_te).to_numpy().ravel()\n",
    "\n",
    "            # Build combined using clin_lp ONLY (not Age/Sex/APOE again)\n",
    "            Xtr_all = pd.concat(\n",
    "                [pd.DataFrame({\"clin_lp\": clin_lp_tr}), Xm_tr_var.reset_index(drop=True)], axis=1\n",
    "            )\n",
    "            Xte_all = pd.concat(\n",
    "                [pd.DataFrame({\"clin_lp\": clin_lp_te}), Xm_te_var.reset_index(drop=True)], axis=1\n",
    "            )\n",
    "\n",
    "            best_comb = fit_select_coxnet_innercv_onese(\n",
    "                Xtr_all, y_tr,\n",
    "                l1_ratio_list=(1.0, 0.5, 0.2),\n",
    "                alpha_grid=np.logspace(-2, 1.2, 50),  # <- start at 1e-2 to avoid instability\n",
    "                n_splits=5\n",
    "            )\n",
    "\n",
    "            risk_comb_te, met_comb = evaluate_coxnet(\n",
    "                best_comb, Xtr_all, y_tr, Xte_all, y_te, \"combined_coxnet\", outdir\n",
    "            )\n",
    "            \n",
    "            # --- Append NOW so the row is guaranteed to be written ---\n",
    "            metrics.append(met_comb)\n",
    "            \n",
    "            # --- Do extra analyses safely; if they fail, keep the row anyway ---\n",
    "            try:\n",
    "                cph_comb = refit_coxph_for_survival(Xtr_all, t_tr, e_tr, penalizer=0.1)\n",
    "                cal_comb = calibration_slope_on_test(cph_comb, Xte_all, t_te, e_te)\n",
    "                brier_comb = brier_and_ibs_clinical(\n",
    "                    cph_comb, Xtr_all, t_tr, e_tr, Xte_all, t_te, e_te, np.array([12,24,36])\n",
    "                )\n",
    "                metrics[-1].update({\"cal_slope\": cal_comb, **brier_comb})\n",
    "                metrics[-1].update(\n",
    "                    add_bootstrap_cis_to_metrics({}, y_tr, y_te, risk_comb_te, times=(12,24,36), n_boot=300)\n",
    "                )\n",
    "                save_calibration_plot_and_csv(\n",
    "                    cph_comb, Xte_all, t_te, e_te, 24,\n",
    "                    os.path.join(outdir, \"calibration_24m_combined\"),\n",
    "                    \"Calibration — Combined @24m\",\n",
    "                    n_bins=6\n",
    "                )\n",
    "            \n",
    "                # ---- DCA @ 24m for COMBINED (using cph_comb) ----\n",
    "                p24_comb = predict_event_prob_by_time_cph(cph_comb, Xte_all, t_months=24)\n",
    "                dca24_comb = decision_curve_net_benefit(\n",
    "                    t_te, e_te, p24_comb, thresholds=np.linspace(0.05, 0.5, 10), horizon_months=24\n",
    "                )\n",
    "                dca24_comb.to_csv(os.path.join(outdir, \"dca_combined_24m.csv\"), index=False)\n",
    "                plot_dca(dca24_comb, os.path.join(outdir, \"dca_combined_24m.png\"),\n",
    "                         \"Decision Curve — Combined (24m)\")\n",
    "            \n",
    "                try:\n",
    "                    cph_comb.check_assumptions(\n",
    "                        pd.concat([pd.DataFrame({\"time\": t_tr, \"event\": e_tr}), Xtr_all], axis=1),\n",
    "                        p_value_threshold=0.05, show_plots=False\n",
    "                    )\n",
    "                except Exception:\n",
    "                    pass\n",
    "            except Exception as ex:\n",
    "                print(\"[Combined] Skipped extras due to:\", type(ex).__name__, str(ex))\n",
    "\n",
    "\n",
    "            # ---- DCA @ 24m for miRNA-only (using cph_mir) ----\n",
    "            p24_mir = predict_event_prob_by_time_cph(cph_mir, Xm_te_var, t_months=24)\n",
    "            dca24_mir = decision_curve_net_benefit(\n",
    "                t_te, e_te, p24_mir, thresholds=np.linspace(0.05, 0.5, 10), horizon_months=24\n",
    "            )\n",
    "            dca24_mir.to_csv(os.path.join(outdir, \"dca_miRNA_24m.csv\"), index=False)\n",
    "            plot_dca(dca24_mir, os.path.join(outdir, \"dca_miRNA_24m.png\"),\n",
    "                     \"Decision Curve — miRNA-only (24m)\")\n",
    "\n",
    "            # ---- DCA @ 24m for COMBINED (using cph_comb) ----\n",
    "            p24_comb = predict_event_prob_by_time_cph(cph_comb, Xte_all, t_months=24)\n",
    "            dca24_comb = decision_curve_net_benefit(\n",
    "                t_te, e_te, p24_comb, thresholds=np.linspace(0.05, 0.5, 10), horizon_months=24\n",
    "            )\n",
    "            dca24_comb.to_csv(os.path.join(outdir, \"dca_combined_24m.csv\"), index=False)\n",
    "            plot_dca(dca24_comb, os.path.join(outdir, \"dca_combined_24m.png\"),\n",
    "                     \"Decision Curve — Combined (24m)\")\n",
    "\n",
    "            # ---- Overlay plot (all three on one figure) ----\n",
    "            plot_dca_compare(\n",
    "                {\"Clinical\": dca24, \"miRNA-only\": dca24_mir, \"Combined\": dca24_comb},\n",
    "                os.path.join(outdir, \"dca_compare_24m.png\"),\n",
    "                \"Decision Curve — 24 months (overlay)\"\n",
    "            )\n",
    "\n",
    "            if try_rsf:\n",
    "                risk_rsf_te, met_rsf = fit_eval_rsf(\n",
    "                    Xtr_all.values, y_tr, Xte_all.values, y_te, \"combined_rsf\", outdir\n",
    "                )\n",
    "                metrics.append(met_rsf)\n",
    "\n",
    "\n",
    "            # Patient-level predictions for dashboard\n",
    "            pred_df = pd.DataFrame({\n",
    "                \"ID\": ids[te_idx],\n",
    "                \"time_months\": t_te,\n",
    "                \"event\": e_te,\n",
    "                \"risk_clinical\": risk_clin_te,\n",
    "                \"risk_miRNA_coxnet\": risk_mir_te,\n",
    "                \"risk_combined_coxnet\": risk_comb_te\n",
    "            })\n",
    "            pred_df.to_csv(os.path.join(outdir, \"patient_level_predictions_test.csv\"), index=False)\n",
    "\n",
    "        except Exception as ex:\n",
    "            import traceback\n",
    "            print(\"Coxnet block failed:\", type(ex).__name__, str(ex))\n",
    "            traceback.print_exc()\n",
    "            print(\"Continuing with clinical outputs only.\")\n",
    "\n",
    "    # 8) Save top-level metrics table\n",
    "    pd.DataFrame(metrics).to_csv(os.path.join(outdir, \"model_metrics.csv\"), index=False)\n",
    "\n",
    "    # 9) Freeze environment for reproducibility\n",
    "    try:\n",
    "        import pkg_resources\n",
    "        with open(os.path.join(outdir, \"requirements_freeze.txt\"), \"w\") as f:\n",
    "            for dist in sorted(pkg_resources.working_set, key=lambda d: d.project_name.lower()):\n",
    "                f.write(f\"{dist.project_name}=={dist.version}\\n\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 10) Console checklist\n",
    "    print(\"\\n== DONE. See outputs/ ==\")\n",
    "    print(\" - baseline_table_raw.csv\")\n",
    "    print(\" - clinical_cox_hazard_ratios.csv\")\n",
    "    print(\" - model_metrics.csv\")\n",
    "    print(\" - km_by_risk_tertiles_clinical.png\")\n",
    "    if SKSURV_OK and ENABLE_PENALIZED:\n",
    "        print(\" - miRNA_screened_features.csv\")\n",
    "        print(\" - km_by_risk_tertiles_miRNA_coxnet.png\")\n",
    "        print(\" - km_by_risk_tertiles_combined_coxnet.png\")\n",
    "        print(\" - miRNA_coxnet_nonzero_coeffs.csv\")\n",
    "        print(\" - combined_coxnet_nonzero_coeffs.csv\")\n",
    "        print(\" - patient_level_predictions_test.csv\")\n",
    "    print(\" - dca_clinical_24m.csv\")\n",
    "    print(\" - metrics_subgroups_clinical.csv\")\n",
    "    print(\" - requirements_freeze.txt\")\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Entrypoint\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main(\n",
    "        csv_path=\"file path redacted for privacy",\n",
    "        outdir=\"outputs\",\n",
    "        seed=123,\n",
    "        test_frac=0.25,\n",
    "        try_rsf=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ab8b9-3226-4264-8d6b-6322c18a7a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e41398-eaed-42b0-9c02-08e8e75de120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acecabc-6124-4d1d-82b6-82b28cc71164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478f252-b146-465d-beb8-6218b278ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
